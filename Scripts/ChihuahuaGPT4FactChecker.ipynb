{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import snowflake.connector\n",
    "from tqdm import tqdm\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty df called subdf\n",
    "subdf = pd.DataFrame(columns=['project_id','project_name'])\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64d3b33e2bc9a62e70ecce39', 'project_name':'Biology '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de62829672f1286b545cc0', 'project_name':'Statistics and Probability'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de63dbe1df5ee41eb0bdc5', 'project_name':'Computer Science'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de642d4294b1b0d5af25f2', 'project_name':'Earth Sciences'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64744d0f3ac2d028a0a7', 'project_name':'Chemistry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de648e0d52011b4702b175', 'project_name':'Geometry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64dd840356ab663fcd219d99', 'project_name':'Algebra '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64c40948dc7f0d98b75b', 'project_name':'Prealgebra'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64ff3155c680b93549c0', 'project_name':'Precalculus'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6516ea56fa4cb04ba160', 'project_name':'Trigonometry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6587a1472e3a571020df', 'project_name':'Advanced Math'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de654d92add42bcfeeb0e9', 'project_name':'Calculus'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de65a2ea56fa4cb04bc328', 'project_name':'Other Math '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de65d3a6e7fd7726c4ab40', 'project_name':'Advanced Physics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de660e1c964afee02f261f', 'project_name':'Physics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de664d426fb9f03c83e73d', 'project_name':'Accounting'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6687d1f6b586efeb1596', 'project_name':'Economics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de66afc83a82961258add5', 'project_name':'Finance'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de66eb4f5c495d231a2eb8', 'project_name':'Operations Management '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de671505668ea875fa5fe0', 'project_name':'Anatomy and Physiology'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de672c93ad3f1536108882', 'project_name':'Nursing'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6755d6a2362a21ae97f9', 'project_name':'Psychology '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de67aef168bd56beb6b1d7', 'project_name':'Chemical Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de68117063e52806e3dfb5', 'project_name':'Civil Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de684c2fb5611b24ccacc3', 'project_name':'Electrical Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de688b102709fde54a6a21', 'project_name':'Mechanical Engineering'}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "#login to snowflake db\n",
    "con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='COMPUTE_WH',\n",
    "                                 database='SCALE_PROD',\n",
    "                                 role='GENERAL_RO')\n",
    "cs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timeout handler function\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError()\n",
    "\n",
    "# Set the signal to call the handler on alarm\n",
    "signal.signal(signal.SIGALRM, handler)\n",
    "\n",
    "\n",
    "def get_data_sample(cs, project_id):  \n",
    "    try:\n",
    "        # Set an alarm for 8 minutes\n",
    "        signal.alarm(8 * 60)\n",
    "\n",
    "        # Get work logs\n",
    "        sql = f'''\n",
    "        select\n",
    "        ta.task as task_id,\n",
    "        ta.response:responses[0]:output::string as prompt_input,\n",
    "        ta.response:responses[1]:output::string as ModelResponseSelector_01,\n",
    "        ta.response:responses[2]:output::string as ModelResponseEditor_01,\n",
    "        ta.response:responses[3]:output::string as MultiTurnContinue_01,\n",
    "        ta.response:responses[4]:output::string as ModelResponseSelector_02,\n",
    "        ta.response:responses[5]:output::string as ModelResponseEditor_02,\n",
    "        ta.response:responses[6]:output::string as MultiTurnContinue_02,\n",
    "        ta.response:responses[7]:output::string as ModelResponseSelector_03,\n",
    "        ta.response:responses[8]:output::string as ModelResponseEditor_03,\n",
    "        ta.response:responses[9]:output::string as MultiTurnContinue_03,\n",
    "        ta.response:responses[10]:output::string as ModelResponseSelector_04,\n",
    "        ta.response:responses[11]:output::string as ModelResponseEditor_04,\n",
    "        ta.response:responses[12]:output::string as MultiTurnContinue_04,\n",
    "        ta.response:responses[13]:output::string as ModelResponseSelector_05,\n",
    "        ta.response:responses[14]:output::string as ModelResponseEditor_05,\n",
    "        ta.response:responses[15]:output::string as MultiTurnContinue_05,\n",
    "        ta.response:responses[16]:output::string as ModelResponseSelector_06,\n",
    "        ta.response:responses[17]:output::string as ModelResponseEditor_06,\n",
    "        ta.response:responses[18]:output::string as MultiTurnContinue_06,\n",
    "        ta.response:responses[19]:output::string as ModelResponseSelector_07,\n",
    "        ta.response:responses[20]:output::string as ModelResponseEditor_07\n",
    "        from\n",
    "        taskattempts ta\n",
    "        left join tasks t on t._ID=ta.task\n",
    "        where\n",
    "        t.status = 'completed'\n",
    "        and ta.project = '{project_id}' \n",
    "        limit\n",
    "        10\n",
    "        '''\n",
    "        cs.execute(sql)\n",
    "        rdf = cs.fetch_pandas_all()\n",
    "\n",
    "        # Deactivate the alarm\n",
    "        signal.alarm(0)\n",
    "        return rdf\n",
    "\n",
    "    except TimeoutError:\n",
    "        return \"Timeout Exception\"\n",
    "    except Exception as e:\n",
    "        return \"Unknown Error\"\n",
    "\n",
    "\n",
    "def get_response(rdf, project_id, project_name):\n",
    "    \n",
    "# Create loop to iterate through each row of the dataframe with progress bar\n",
    "    for index, row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "            #create and empty dataframe called tdf with columns project, task_id, response, assessment, reqid\n",
    "            tdf = pd.DataFrame(columns=['project', 'task_id', 'response', 'assessment', 'reqid'])\n",
    "            # Save the current row in a variable called res\n",
    "            task_id = row['TASK_ID']\n",
    "            res = row['RESPONSE_FINAL']\n",
    "            data = {\n",
    "                \"input\": {\n",
    "                    \"input\": res \n",
    "                }\n",
    "            }\n",
    "            headers = {\"Authorization\": \"Basic clfv6zfnd011k1arec1lucb9l\"}\n",
    "            response = requests.post(\n",
    "                \"https://dashboard.scale.com/spellbook/api/v2/deploy/2m03uo1\",\n",
    "                json=data,\n",
    "                headers=headers\n",
    "            )\n",
    "            # Save the 'output' value in response.json() in a variable called result\n",
    "            result = response.json()['output']\n",
    "            reqid = response.json()['requestId']\n",
    "            # Create a new temporary dataframe\n",
    "            temp_df = pd.DataFrame([{'project_id':project_id, 'project_name':project_name, 'task_id':task_id, 'response': res, 'assessment': result, 'reqid': reqid}])\n",
    "            # Concatenate the temporary dataframe to tdf\n",
    "            tdf = pd.concat([tdf, temp_df], ignore_index=True)\n",
    "            #save tdf as csv with name project_name.csv            \n",
    "            tdf.to_csv(project_name + '.csv', index=False)\n",
    "    return tdf\n",
    "\n",
    "\n",
    "\n",
    "def data_prep(rdf):\n",
    "    try:\n",
    "        # Convert each column to string and then concatenate\n",
    "        rdf['RESPONSE_FINAL'] = (\n",
    "            rdf['MODELRESPONSEEDITOR_01'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_02'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_03'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_04'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_05'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_06'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_07'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Remove all newline characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('\\n', ' ')\n",
    "        # Remove all &#x20; characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('&#x20;', ' ')\n",
    "        # Remove all 'None' characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('None', ' ')\n",
    "\n",
    "        # Remove rows with duplicate task_id\n",
    "        rdf.drop_duplicates(subset=['TASK_ID'], inplace=True)\n",
    "\n",
    "        # Drop ModelResponseEditor columns\n",
    "        rdf.drop(columns=['MODELRESPONSEEDITOR_01', 'MODELRESPONSEEDITOR_02', 'MODELRESPONSEEDITOR_03', 'MODELRESPONSEEDITOR_04', 'MODELRESPONSEEDITOR_05', 'MODELRESPONSEEDITOR_06', 'MODELRESPONSEEDITOR_07'], inplace=True)\n",
    "\n",
    "        # Drop MultiTurnContinue columns\n",
    "        rdf.drop(columns=['MULTITURNCONTINUE_01', 'MULTITURNCONTINUE_02', 'MULTITURNCONTINUE_03', 'MULTITURNCONTINUE_04', 'MULTITURNCONTINUE_05', 'MULTITURNCONTINUE_06'], inplace=True)\n",
    "\n",
    "        # Drop ModelResponseSelector columns\n",
    "        rdf.drop(columns=['MODELRESPONSESELECTOR_01', 'MODELRESPONSESELECTOR_02', 'MODELRESPONSESELECTOR_03', 'MODELRESPONSESELECTOR_04', 'MODELRESPONSESELECTOR_05', 'MODELRESPONSESELECTOR_06', 'MODELRESPONSESELECTOR_07'], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "    return rdf\n",
    "\n",
    "\n",
    "def score_calc(tdf, project_name):\n",
    "    # Count total rows excluding header row in tdf\n",
    "    total_rows = len(tdf.index)\n",
    "    # Count the number of rows where GPT4_Assessment is 'No errors'\n",
    "    count = len(tdf[tdf['assessment'] == 'No Error'].index)\n",
    "    # Calculate accuracy\n",
    "    accuracy = count / total_rows\n",
    "    # Print accuracy\n",
    "    print(project_name,\" factual accuracy is \", accuracy * 100, \"%\")\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sample response data for project  Biology \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52/52 [01:05<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biology   factual accuracy is  100.0 %\n",
      "Getting sample response data for project  Accounting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 45/45 [01:00<00:00,  1.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accounting  factual accuracy is  100.0 %\n",
      "Getting sample response data for project  Electrical Engineering\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 12/56 [00:17<00:51,  1.16s/it]"
     ]
    }
   ],
   "source": [
    "#random shuffle the rows of subdf\n",
    "subdf = subdf.sample(frac=1).reset_index(drop=True)\n",
    "#start a for loop to loop through each row of subdf\n",
    "for index, row in subdf.iterrows():\n",
    "    # Call get_data_sample function and save the returned dataframe in a variable called rdf\n",
    "    print(\"Getting sample response data for project \",row['project_name'])\n",
    "    rdf = get_data_sample(cs, row['project_id'])\n",
    "    # Call data_prep function and save the returned dataframe in a variable called rdf\n",
    "    rdf = data_prep(rdf)\n",
    "    # Call get_response function and save the returned dataframe in a variable called tdf\n",
    "    tdf = get_response(rdf, row['project_id'], row['project_name'])\n",
    "    # Call score_calc function and save the returned dataframe in a variable called tdf\n",
    "    accuracy = score_calc(tdf, row['project_name'])\n",
    "    # Save calculated accuracy in a dataframe called SubjectScores\n",
    "    SubjectScores = pd.DataFrame([{'project_name':row['project_name'], 'accuracy': accuracy}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
