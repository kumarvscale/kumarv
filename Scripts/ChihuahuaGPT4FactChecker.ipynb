{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import snowflake.connector\n",
    "from tqdm import tqdm\n",
    "import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty df called subdf\n",
    "subdf = pd.DataFrame(columns=['project_id','project_name'])\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64d3b33e2bc9a62e70ecce39', 'project_name':'Biology '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de62829672f1286b545cc0', 'project_name':'Statistics and Probability'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de63dbe1df5ee41eb0bdc5', 'project_name':'Computer Science'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de642d4294b1b0d5af25f2', 'project_name':'Earth Sciences'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64744d0f3ac2d028a0a7', 'project_name':'Chemistry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de648e0d52011b4702b175', 'project_name':'Geometry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64dd840356ab663fcd219d99', 'project_name':'Algebra '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64c40948dc7f0d98b75b', 'project_name':'Prealgebra'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de64ff3155c680b93549c0', 'project_name':'Precalculus'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6516ea56fa4cb04ba160', 'project_name':'Trigonometry'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6587a1472e3a571020df', 'project_name':'Advanced Math'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de654d92add42bcfeeb0e9', 'project_name':'Calculus'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de65a2ea56fa4cb04bc328', 'project_name':'Other Math '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de65d3a6e7fd7726c4ab40', 'project_name':'Advanced Physics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de660e1c964afee02f261f', 'project_name':'Physics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de664d426fb9f03c83e73d', 'project_name':'Accounting'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6687d1f6b586efeb1596', 'project_name':'Economics'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de66afc83a82961258add5', 'project_name':'Finance'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de66eb4f5c495d231a2eb8', 'project_name':'Operations Management '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de671505668ea875fa5fe0', 'project_name':'Anatomy and Physiology'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de672c93ad3f1536108882', 'project_name':'Nursing'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de6755d6a2362a21ae97f9', 'project_name':'Psychology '}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de67aef168bd56beb6b1d7', 'project_name':'Chemical Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de68117063e52806e3dfb5', 'project_name':'Civil Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de684c2fb5611b24ccacc3', 'project_name':'Electrical Engineering'}])], ignore_index=True)\n",
    "subdf = pd.concat([subdf, pd.DataFrame([{'project_id': '64de688b102709fde54a6a21', 'project_name':'Mechanical Engineering'}])], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "#login to snowflake db\n",
    "con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='COMPUTE_WH',\n",
    "                                 database='SCALE_PROD',\n",
    "                                 role='GENERAL_RO')\n",
    "cs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the timeout handler function\n",
    "def handler(signum, frame):\n",
    "    raise TimeoutError()\n",
    "\n",
    "# Set the signal to call the handler on alarm\n",
    "signal.signal(signal.SIGALRM, handler)\n",
    "\n",
    "\n",
    "def get_data_sample(cs, project_id):  \n",
    "    try:\n",
    "        # Set an alarm for 8 minutes\n",
    "        signal.alarm(8 * 60)\n",
    "\n",
    "        # Get work logs\n",
    "        sql = f'''\n",
    "        select\n",
    "        ta.task as task_id,\n",
    "        ta.response:responses[0]:output::string as prompt_input,\n",
    "        ta.response:responses[1]:output::string as ModelResponseSelector_01,\n",
    "        ta.response:responses[2]:output::string as ModelResponseEditor_01,\n",
    "        ta.response:responses[3]:output::string as MultiTurnContinue_01,\n",
    "        ta.response:responses[4]:output::string as ModelResponseSelector_02,\n",
    "        ta.response:responses[5]:output::string as ModelResponseEditor_02,\n",
    "        ta.response:responses[6]:output::string as MultiTurnContinue_02,\n",
    "        ta.response:responses[7]:output::string as ModelResponseSelector_03,\n",
    "        ta.response:responses[8]:output::string as ModelResponseEditor_03,\n",
    "        ta.response:responses[9]:output::string as MultiTurnContinue_03,\n",
    "        ta.response:responses[10]:output::string as ModelResponseSelector_04,\n",
    "        ta.response:responses[11]:output::string as ModelResponseEditor_04,\n",
    "        ta.response:responses[12]:output::string as MultiTurnContinue_04,\n",
    "        ta.response:responses[13]:output::string as ModelResponseSelector_05,\n",
    "        ta.response:responses[14]:output::string as ModelResponseEditor_05,\n",
    "        ta.response:responses[15]:output::string as MultiTurnContinue_05,\n",
    "        ta.response:responses[16]:output::string as ModelResponseSelector_06,\n",
    "        ta.response:responses[17]:output::string as ModelResponseEditor_06,\n",
    "        ta.response:responses[18]:output::string as MultiTurnContinue_06,\n",
    "        ta.response:responses[19]:output::string as ModelResponseSelector_07,\n",
    "        ta.response:responses[20]:output::string as ModelResponseEditor_07\n",
    "        from\n",
    "        taskattempts ta\n",
    "        left join tasks t on t._ID=ta.task\n",
    "        where\n",
    "        t.status = 'completed'\n",
    "        and ta.project = '{project_id}' \n",
    "        limit\n",
    "        120\n",
    "        '''\n",
    "        cs.execute(sql)\n",
    "        rdf = cs.fetch_pandas_all()\n",
    "\n",
    "        # Deactivate the alarm\n",
    "        signal.alarm(0)\n",
    "        return rdf\n",
    "\n",
    "    except TimeoutError:\n",
    "        return \"Timeout Exception\"\n",
    "    except Exception as e:\n",
    "        return \"Unknown Error\"\n",
    "\n",
    "\n",
    "def get_response(rdf, project_id, project_name):\n",
    "    tdf = pd.DataFrame(columns=['project', 'task_id', 'response', 'assessment', 'reqid'])    \n",
    "# Create loop to iterate through each row of the dataframe with progress bar\n",
    "    for index, row in tqdm(rdf.iterrows(), total=rdf.shape[0]):\n",
    "            #create and empty dataframe called tdf with columns project, task_id, response, assessment, reqid\n",
    "            \n",
    "            # Save the current row in a variable called res\n",
    "            task_id = row['TASK_ID']\n",
    "            res = row['RESPONSE_FINAL']\n",
    "            data = {\n",
    "                \"input\": {\n",
    "                    \"input\": res \n",
    "                }\n",
    "            }\n",
    "            headers = {\"Authorization\": \"Basic clfv6zfnd011k1arec1lucb9l\"}\n",
    "            response = requests.post(\n",
    "                \"https://dashboard.scale.com/spellbook/api/v2/deploy/2m03uo1\",\n",
    "                json=data,\n",
    "                headers=headers\n",
    "            )\n",
    "            # Save the 'output' value in response.json() in a variable called result\n",
    "            result = response.json()['output']\n",
    "            reqid = response.json()['requestId']\n",
    "            # Create a new temporary dataframe\n",
    "            temp_df = pd.DataFrame([{'project_id':project_id, 'project_name':project_name, 'task_id':task_id, 'response': res, 'assessment': result, 'reqid': reqid}])\n",
    "            # Concatenate the temporary dataframe to tdf\n",
    "            tdf = pd.concat([tdf, temp_df], ignore_index=True)\n",
    "            #save tdf as csv with name project_name.csv            \n",
    "            tdf.to_csv(project_name + '.csv', index=False)\n",
    "    return tdf\n",
    "\n",
    "\n",
    "\n",
    "def data_prep(rdf):\n",
    "    try:\n",
    "        # Convert each column to string and then concatenate\n",
    "        rdf['RESPONSE_FINAL'] = (\n",
    "            rdf['MODELRESPONSEEDITOR_01'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_02'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_03'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_04'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_05'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_06'].astype(str) +\n",
    "            rdf['MODELRESPONSEEDITOR_07'].astype(str)\n",
    "        )\n",
    "        \n",
    "        # Remove all newline characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('\\n', ' ')\n",
    "        # Remove all &#x20; characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('&#x20;', ' ')\n",
    "        # Remove all 'None' characters from RESPONSE_FINAL and replace with space\n",
    "        rdf['RESPONSE_FINAL'] = rdf['RESPONSE_FINAL'].str.replace('None', ' ')\n",
    "\n",
    "        # Remove rows with duplicate task_id\n",
    "        rdf.drop_duplicates(subset=['TASK_ID'], inplace=True)\n",
    "\n",
    "        # Drop ModelResponseEditor columns\n",
    "        rdf.drop(columns=['MODELRESPONSEEDITOR_01', 'MODELRESPONSEEDITOR_02', 'MODELRESPONSEEDITOR_03', 'MODELRESPONSEEDITOR_04', 'MODELRESPONSEEDITOR_05', 'MODELRESPONSEEDITOR_06', 'MODELRESPONSEEDITOR_07'], inplace=True)\n",
    "\n",
    "        # Drop MultiTurnContinue columns\n",
    "        rdf.drop(columns=['MULTITURNCONTINUE_01', 'MULTITURNCONTINUE_02', 'MULTITURNCONTINUE_03', 'MULTITURNCONTINUE_04', 'MULTITURNCONTINUE_05', 'MULTITURNCONTINUE_06'], inplace=True)\n",
    "\n",
    "        # Drop ModelResponseSelector columns\n",
    "        rdf.drop(columns=['MODELRESPONSESELECTOR_01', 'MODELRESPONSESELECTOR_02', 'MODELRESPONSESELECTOR_03', 'MODELRESPONSESELECTOR_04', 'MODELRESPONSESELECTOR_05', 'MODELRESPONSESELECTOR_06', 'MODELRESPONSESELECTOR_07'], inplace=True)\n",
    "    except Exception as e:\n",
    "        print(\"error\")\n",
    "    return rdf\n",
    "\n",
    "\n",
    "def score_calc(tdf, project_name):\n",
    "    # Count total rows excluding header row in tdf\n",
    "    total_rows = len(tdf.index)\n",
    "    # Count the number of rows where GPT4_Assessment is 'No errors'\n",
    "    count = len(tdf[tdf['assessment'] == 'No Error'].index)\n",
    "    # Calculate accuracy\n",
    "    accuracy = count / total_rows\n",
    "    # Print accuracy\n",
    "    print(project_name,\" factual accuracy is \", accuracy * 100, \"%\")\n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting sample response data for project  Biology \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:13<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biology   factual accuracy is  95.52238805970148 %\n",
      "Getting sample response data for project  Statistics and Probability\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63/63 [01:21<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics and Probability  factual accuracy is  79.36507936507937 %\n",
      "Getting sample response data for project  Computer Science\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:53<00:00,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer Science  factual accuracy is  82.5 %\n",
      "Getting sample response data for project  Earth Sciences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [01:12<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earth Sciences  factual accuracy is  83.63636363636363 %\n",
      "Getting sample response data for project  Chemistry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61/61 [01:52<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chemistry  factual accuracy is  72.1311475409836 %\n",
      "Getting sample response data for project  Geometry\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [01:48<00:00,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Geometry  factual accuracy is  56.25 %\n",
      "Getting sample response data for project  Algebra \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [02:08<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algebra   factual accuracy is  53.333333333333336 %\n",
      "Getting sample response data for project  Prealgebra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [01:27<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prealgebra  factual accuracy is  51.28205128205128 %\n",
      "Getting sample response data for project  Precalculus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 31/55 [01:13<00:56,  2.36s/it]\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:971\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39;49mloads(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtext, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m rdf \u001b[39m=\u001b[39m data_prep(rdf)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# Call get_response function and save the returned dataframe in a variable called tdf\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m tdf \u001b[39m=\u001b[39m get_response(rdf, row[\u001b[39m'\u001b[39;49m\u001b[39mproject_id\u001b[39;49m\u001b[39m'\u001b[39;49m], row[\u001b[39m'\u001b[39;49m\u001b[39mproject_name\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Call score_calc function and save the returned dataframe in a variable called tdf\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m accuracy \u001b[39m=\u001b[39m score_calc(tdf, row[\u001b[39m'\u001b[39m\u001b[39mproject_name\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[1;32m/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb Cell 5\u001b[0m in \u001b[0;36mget_response\u001b[0;34m(rdf, project_id, project_name)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhttps://dashboard.scale.com/spellbook/api/v2/deploy/2m03uo1\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=77'>78</a>\u001b[0m     json\u001b[39m=\u001b[39mdata,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=78'>79</a>\u001b[0m     headers\u001b[39m=\u001b[39mheaders\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m \u001b[39m# Save the 'output' value in response.json() in a variable called result\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39;49mjson()[\u001b[39m'\u001b[39m\u001b[39moutput\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m reqid \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()[\u001b[39m'\u001b[39m\u001b[39mrequestId\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/ChihuahuaGPT4FactChecker.ipynb#W4sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m \u001b[39m# Create a new temporary dataframe\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/requests/models.py:975\u001b[0m, in \u001b[0;36mResponse.json\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m     \u001b[39mreturn\u001b[39;00m complexjson\u001b[39m.\u001b[39mloads(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    972\u001b[0m \u001b[39mexcept\u001b[39;00m JSONDecodeError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    973\u001b[0m     \u001b[39m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[1;32m    974\u001b[0m     \u001b[39m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m     \u001b[39mraise\u001b[39;00m RequestsJSONDecodeError(e\u001b[39m.\u001b[39mmsg, e\u001b[39m.\u001b[39mdoc, e\u001b[39m.\u001b[39mpos)\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#start a for loop to loop through each row of subdf\n",
    "for index, row in subdf.iterrows():\n",
    "    # Call get_data_sample function and save the returned dataframe in a variable called rdf\n",
    "    print(\"Getting sample response data for project \",row['project_name'])\n",
    "    rdf = get_data_sample(cs, row['project_id'])\n",
    "    # Call data_prep function and save the returned dataframe in a variable called rdf\n",
    "    rdf = data_prep(rdf)\n",
    "    # Call get_response function and save the returned dataframe in a variable called tdf\n",
    "    tdf = get_response(rdf, row['project_id'], row['project_name'])\n",
    "    # Call score_calc function and save the returned dataframe in a variable called tdf\n",
    "    accuracy = score_calc(tdf, row['project_name'])\n",
    "    # Save calculated accuracy in a dataframe called SubjectScores\n",
    "    SubjectScores = pd.DataFrame([{'project_name':row['project_name'], 'accuracy': accuracy}])\n",
    "\n",
    "# Save SubjectScores as csv\n",
    "SubjectScores.to_csv('SubjectScores.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
