{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7404b5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "# In[1]:\n",
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import snowflake.connector\n",
    "import boto3\n",
    "from __future__ import print_function\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import random\n",
    "import concurrent.futures\n",
    "import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1aa088f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "# ## Setup\n",
    "# ### Credentials\n",
    "# In[2]:\n",
    "## https://developers.google.com/sheets/api/quickstart/python\n",
    "\n",
    "# Google Sheets\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets.readonly']\n",
    "SPREADSHEET_ID = '18WNpqJ1v4NRAkQG6M2VqPMKqO5JdxS2gRyUVNUmbqGU'\n",
    "RANGE_NAME = \"'Batch 8'!A:B\"\n",
    "PATH_TO_SECRETS_FILE = 'credentials.json'\n",
    "creds = None\n",
    "\n",
    "# Snowflake\n",
    "con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='COMPUTE_WH',\n",
    "                                 database='SCALE_CRAWLER',\n",
    "                                 role='GENERAL_RO')\n",
    "cs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d3e62a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corp\n",
    "CORP_KEY = 'scaleint_26e8b448701e41b9bc1128152129ced9'\n",
    "CUSTOMER_KEY = '608748001b4605002c151701'\n",
    "LIVE_API_KEY = f'{CORP_KEY}|{CUSTOMER_KEY}'\n",
    "ENDPOINT = \"textcollection\"\n",
    "PROJECT = 'Post-Processing Claim Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4e572a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task payload\n",
    "FIELDS = [\n",
    "    {\n",
    "      \"type\": \"category\",\n",
    "      \"field_id\": \"auditLevel\",\n",
    "      \"title\": \"Audit Level\",\n",
    "      \"required\": 'true',\n",
    "      \"description\": \"Select the level at which you are auditing this site\",\n",
    "      \"choices\": [\n",
    "        {\n",
    "          \"label\": \"QA\",\n",
    "          \"value\": \"qa\"\n",
    "        },\n",
    "        {\n",
    "          \"label\": \"Spotter\",\n",
    "          \"value\": \"spotter\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"category\",\n",
    "      \"field_id\": \"spotterChanges\",\n",
    "      \"title\": \"Did you need to makes changes to this site?\",\n",
    "      \"required\": 'true',\n",
    "      \"choices\": [\n",
    "        {\n",
    "          \"label\": \"Yes\",\n",
    "          \"value\": \"yes\"\n",
    "        },\n",
    "        {\n",
    "          \"label\": \"No\",\n",
    "          \"value\": \"no\"\n",
    "        }\n",
    "      ],\n",
    "      \"conditions\": [\n",
    "        {\n",
    "          \"auditLevel\": [\n",
    "            \"spotter\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"text\",\n",
    "      \"field_id\": \"changesMade\",\n",
    "      \"title\": \"Changes made\",\n",
    "      \"description\": \"Any notes of what you fixed\",\n",
    "      \"conditions\": [\n",
    "        {\n",
    "          \"spotterChanges\": [\n",
    "            \"yes\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"text\",\n",
    "      \"field_id\": \"QAQuestions\",\n",
    "      \"title\": \"Questions?\",\n",
    "      \"description\": \"Use this field to note any questions / confusions you have!\",\n",
    "      \"conditions\": [\n",
    "        {\n",
    "          \"auditLevel\": [\n",
    "            \"qa\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"type\": \"text\",\n",
    "      \"field_id\": \"spotterQuestions\",\n",
    "      \"title\": \"Questions?\",\n",
    "      \"description\": \"Use this field to note any questions / confusions you have!\",\n",
    "      \"conditions\": [\n",
    "        {\n",
    "          \"auditLevel\": [\n",
    "            \"spotter\"\n",
    "          ]\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ]\n",
    "ATTACHMENT = '''\n",
    "<ol>\n",
    "    <li>Post-process <a href=\"{url}\" target=\"_blank\">this site segment</a></li>\n",
    "    <li>Submit the task when you are finished</li>\n",
    "</ol>\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e55e0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Inputs\n",
    "# In[57]:\n",
    "\n",
    "max_desc_per_set = 300\n",
    "# sample_sites = ['surfnwearbeachhouse.com', # big site 7975 desc\n",
    "#                 'www.fancybands.net', # medium site 606 desc\n",
    "#                 'www.tinyorganics.com'] # small site 23 desc\n",
    "\n",
    "sample_sites = ['www.sitnsleep.com','mulco.com']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9cf6a42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ## Get data\n",
    "\n",
    "# In[58]:\n",
    "\n",
    "\n",
    "# def pullFromGS(SCOPES,PATH_TO_SECRETS_FILE,creds,SPREADSHEET_ID,RANGE_NAME):\n",
    "#     if os.path.exists('token.json'):\n",
    "#         creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "\n",
    "#     if not creds or not creds.valid:\n",
    "#         if creds and creds.expired and creds.refresh_token:\n",
    "#             creds.refresh(Request())\n",
    "#         else:\n",
    "#             flow = InstalledAppFlow.from_client_secrets_file(PATH_TO_SECRETS_FILE, SCOPES)\n",
    "#             creds = flow.run_local_server(port=0)\n",
    "#         with open('token.json', 'w') as token:\n",
    "#             token.write(creds.to_json())\n",
    "\n",
    "#     try:\n",
    "#         service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "#         sheet = service.spreadsheets()\n",
    "#         result = sheet.values().get(spreadsheetId=SPREADSHEET_ID,range=RANGE_NAME).execute()\n",
    "#         values = result.get('values', [])\n",
    "\n",
    "#         if not values:\n",
    "#             print('No data found.')\n",
    "        \n",
    "#     except HttpError as err:\n",
    "#         print(err)\n",
    "        \n",
    "#     df = pd.DataFrame(values[1:],columns = values[0])    \n",
    "#     return df\n",
    "\n",
    "\n",
    "def getAllSiteDescriptions():\n",
    "    sql = f'''\n",
    "    select\n",
    "      brand,\n",
    "      count(distinct SCRAPED_ATTRIBUTES :description) ct_description\n",
    "    from\n",
    "      PUBLIC.PRODUCTVARIANTS\n",
    "    where status != 'cancelled'\n",
    "    group by\n",
    "      1\n",
    "    '''\n",
    "    cs.execute(sql)\n",
    "    all_sites = cs.fetch_pandas_all()\n",
    "    return all_sites\n",
    "\n",
    "def getSiteDescriptionSegments(all_sites):\n",
    "    all_sites['num_segment'] = (all_sites['CT_DESCRIPTION'] / max_desc_per_set).apply(np.ceil)\n",
    "    all_site_segments = all_sites.loc[all_sites.index.repeat(all_sites['num_segment'])].reset_index(drop = True)\n",
    "    all_site_segments['segment_index'] = all_site_segments.groupby(['BRAND']).cumcount()\n",
    "    all_site_segments['limit'] = max_desc_per_set    \n",
    "    all_site_segments['skip'] = all_site_segments['segment_index'].apply(lambda x: 0 if x == 0 else max_desc_per_set*x)\n",
    "    all_site_segments['url'] = all_site_segments.apply(lambda x: 'https://dashboard.crawler.scale.com/pdp-qa-dashboard?limitConsolidated=' + str(max_desc_per_set) + '&skipConsolidated=' + str(x['skip']) + '&url=' + x['BRAND'] + '&customer=flamingo', axis = 1)\n",
    "    return all_site_segments\n",
    "\n",
    "def addPriorities(all_site_segments):\n",
    "    batches = pd.DataFrame()\n",
    "    for num in range(4,9): \n",
    "        tmp = pullFromGS(SCOPES,PATH_TO_SECRETS_FILE,creds,SPREADSHEET_ID,f\"'Batch {num}'!A:B\").rename(columns = {'Domain ':'BRAND'})\n",
    "        tmp['batch'] = num\n",
    "        batches = pd.concat([batches,tmp])\n",
    "    dff = all_site_segments.merge(batches, how = 'inner', on = 'BRAND')\n",
    "    dff['priority'] = 1000 - dff['segment_index'] - dff['batch']\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ae275903",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_site_segments = getSiteDescriptionSegments(getAllSiteDescriptions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1ef90d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_payload(url, metadata, attachments = ATTACHMENT, fields = FIELDS,project = PROJECT):\n",
    "    return {\n",
    "        \"project\": PROJECT,\n",
    "        \"instruction\": \" \",\n",
    "        \"callback_url\": \"http://example.com/callback\",\n",
    "        \"fields\": FIELDS,\n",
    "        \"metadata\": metadata,\n",
    "        \"attachments\": [\n",
    "            {\"type\": \"text\",\n",
    "             \"content\": attachments.format(url=url)}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def create_task_request(endpoint, payload, apikey = LIVE_API_KEY):\n",
    "    request_url = \"https://api.scale.com/v1/task/\" + endpoint\n",
    "    headers = {\"Content-Type\": \"application/json\"}\n",
    "    request = requests.post(request_url, json=payload, headers=headers, auth=(apikey, ''))\n",
    "    if request.status_code != 200:\n",
    "        print(\"There was an error at \" + request_url)\n",
    "        print(request.text)\n",
    "        print(payload)\n",
    "        return 0\n",
    "    else:\n",
    "        task_response = request.json()\n",
    "        tracker = payload['metadata']\n",
    "        tracker['task_id'] = task_response['task_id']\n",
    "        return tracker\n",
    "\n",
    "def uploader(row,project_name):\n",
    "    \n",
    "    url = row['url']\n",
    "    metadata = row.to_dict()\n",
    "    \n",
    "    tracker = create_task_request(ENDPOINT, generate_payload(url, metadata),LIVE_API_KEY)\n",
    "    \n",
    "    if tracker == 0:\n",
    "        error_tracker.append(metadata)\n",
    "    else:\n",
    "        id_tracker.append(tracker)\n",
    "       # to_delete.append(tracker['task_id'])\n",
    "    return id_tracker, error_tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b9f2bd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 956.95it/s]\n",
      "5it [00:06,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  6.880970001220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "to_upload = all_site_segments[all_site_segments['BRAND'].isin(sample_sites)]\n",
    "tmp = np.setdiff1d(sample_sites,to_upload.BRAND.unique().tolist())\n",
    "if len(tmp) != 0:\n",
    "    print('Sites NOT included:')\n",
    "    for i in tmp:\n",
    "        print(i)\n",
    "\n",
    "to_upload.groupby('BRAND').count()\n",
    "\n",
    "\n",
    "# In[66]:\n",
    "\n",
    "\n",
    "id_tracker = []\n",
    "error_tracker = []\n",
    "\n",
    "with_threads_start = time.time()\n",
    "with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:\n",
    "    futures = []\n",
    "    for i,row in tqdm(to_upload.iterrows()):\n",
    "        futures.append(executor.submit(uploader,row=row,project_name = PROJECT))\n",
    "    for future in tqdm(concurrent.futures.as_completed(futures)):\n",
    "        (future.result())\n",
    "print(\"Time elapsed: \", time.time() - with_threads_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d4e966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
