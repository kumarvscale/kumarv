{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv and save in idf\n",
    "idf = pd.read_csv('AiredaleEval.csv')\n",
    "# Read openai api key from file apikey.txt\n",
    "api_key_file = 'apikey.txt'\n",
    "if os.path.isfile(api_key_file):\n",
    "    with open(api_key_file) as f:\n",
    "        openai.api_key = f.readline()\n",
    "else:\n",
    "    print(f\"Error: {api_key_file} not found.\")\n",
    "\n",
    "OPENAI_API_KEY = openai.api_key\n",
    "\n",
    "def evaluator_gpt(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[{\"role\":\"user\", \"content\":prompt}],\n",
    "        temperature=0.1\n",
    "    )\n",
    "    # Parse the response to get only the \"content\" part and save it in the response variable\n",
    "    response = completion[\"choices\"][0][\"message\"]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 9/428 [01:21<1:10:15, 10.06s/it]"
     ]
    }
   ],
   "source": [
    "#add following columns to idf: RESPONSE_TOPIC, RESPONSE_SUBTOPIC, RESPONSE_CATEGORY, RESPONSE_GUIDANCE, RESPONSE_COMPLEXITY, RESPONSE_FEEDBACK\n",
    "idf['RESPONSE_TOPIC'] = ''\n",
    "idf['RESPONSE_SUBTOPIC'] = ''\n",
    "idf['RESPONSE_CATEGORY'] = ''\n",
    "idf['RESPONSE_GUIDANCE'] = ''\n",
    "idf['RESPONSE_COMPLEXITY'] = ''\n",
    "idf['RESPONSE_FEEDBACK'] = ''\n",
    "#start a for loop to iterate through the rows of idf and add tqdm to show progress\n",
    "for i in tqdm(range(len(idf))):\n",
    "    #save the column 'MAIN_TOPIC' from current row in a variable called topic\n",
    "    topic = idf['MAIN_TOPIC'][i]\n",
    "    #save the column 'SUB_TOPIC' from current row in a variable called subtopic\n",
    "    subtopic = idf['SUB_TOPIC'][i]\n",
    "    #save the column 'CATEGORY' from current row in a variable called category\n",
    "    category = idf['CATEGORY'][i]\n",
    "    #save the column 'GUIDANCE' from current row in a variable called guidance\n",
    "    guidance = idf['GUIDANCE'][i]\n",
    "    #save the column 'PROMPT' from current row in a variable called text\n",
    "    text = idf['PROMPT'][i]\n",
    "    #write a prompt to check whether the text is relevant to the topic\n",
    "    prompt_topic = \"You are tasked to categorize a given text. You need to check whether the text provided below is relevant to the topic: \" + topic + \".\" + \"\\n\" + \"Please answer 'y' for yes and 'n' for no. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #write a prompt to check whether the text is relevant to the subtopic\n",
    "    prompt_subtopic = \"You are tasked to categorize a given text. You need to check whether the text provided below is relevant to the subtopic: \" + subtopic + \".\" + \"\\n\" + \"Please answer 'y' for yes and 'n' for no. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #write a prompt to check whether the text is relevant to the category\n",
    "    prompt_category = \"You are tasked to categorize a given text. You need to check whether the text provided below is relevant to the category: \" + category + \".\" + \"\\n\" + \"Please answer 'y' for yes and 'n' for no. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #write a prompt to check whether the text is relevant to the guidance\n",
    "    prompt_guidance = \"You are tasked to categorize a given text. You need to check whether the text provided below is relevant to the guidance: \" + guidance + \".\" + \"\\n\" + \"Please answer 'y' for yes and 'n' for no. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #write a prompt for complexity of text\n",
    "    prompt_complexity = \"You are tasked to evaluate the complexity of a given text. A text is complex if it is longer, elbaorate and well written with various instructions included. You need to check whether the text provided below is complex.\" + \"\\n\" + \"Please answer 'y' for yes and 'n' for no. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #write a prompt for one sentence feedback\n",
    "    prompt_feedback = \"You are tasked to provide feedback for a given text. You need to provide feedback on how to make the question more elaborate and well written with various instructions included.\" + \"\\n\" + \"Please provide feedback in one sentence. Do not say anything else\" + \"\\n\" + \"Text: \" + text + \"\\n\"\n",
    "    #save the response from the evaluator_gpt function in a variable called response_topic\n",
    "    response_topic = evaluator_gpt(prompt_topic)\n",
    "    #save the response from the evaluator_gpt function in a variable called response_subtopic\n",
    "    response_subtopic = evaluator_gpt(prompt_subtopic)\n",
    "    #save the response from the evaluator_gpt function in a variable called response_category\n",
    "    response_category = evaluator_gpt(prompt_category)\n",
    "    #save the response from the evaluator_gpt function in a variable called response_guidance\n",
    "    response_guidance = evaluator_gpt(prompt_guidance)\n",
    "    #save the response from the evaluator_gpt function in a variable called response_complexity\n",
    "    response_complexity = evaluator_gpt(prompt_complexity)\n",
    "    #save the response from the evaluator_gpt function in a variable called response_feedback\n",
    "    response_feedback = evaluator_gpt(prompt_feedback)\n",
    "    #save the response_topic in the column 'RESPONSE_TOPIC' of the current row\n",
    "    idf['RESPONSE_TOPIC'][i] = response_topic\n",
    "    #save the response_subtopic in the column 'RESPONSE_SUBTOPIC' of the current row\n",
    "    idf['RESPONSE_SUBTOPIC'][i] = response_subtopic\n",
    "    #save the response_category in the column 'RESPONSE_CATEGORY' of the current row\n",
    "    idf['RESPONSE_CATEGORY'][i] = response_category\n",
    "    #save the response_guidance in the column 'RESPONSE_GUIDANCE' of the current row\n",
    "    idf['RESPONSE_GUIDANCE'][i] = response_guidance\n",
    "    #save the response_complexity in the column 'RESPONSE_COMPLEXITY' of the current row\n",
    "    idf['RESPONSE_COMPLEXITY'][i] = response_complexity\n",
    "    #save the response_feedback in the column 'RESPONSE_FEEDBACK' of the current row\n",
    "    idf['RESPONSE_FEEDBACK'][i] = response_feedback\n",
    "#save idf in a csv file called data_evaluated.csv\n",
    "idf.to_csv('data_evaluated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
