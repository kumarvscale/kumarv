{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\\n                                 account='pxa65918',\\n                                 authenticator='externalbrowser',\\n                                 warehouse='BOOTCAMP_WH',\\n                                 database='SCALE_PLAYPEN',\\n                                 role='SNOWFLAKE_USERS')\\ncs = con.cursor()\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes\n",
    "# LLM (GPT4) is not good at identifying columns names if provided a SQL query (Test conducted using 100 quesry sample and success rate was 44%)\n",
    "\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "#import snowflake.connector\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read openai api key from file apikey.txt\n",
    "api_key_file = 'apikey.txt'\n",
    "if os.path.isfile(api_key_file):\n",
    "    with open(api_key_file) as f:\n",
    "        openai.api_key = f.readline()\n",
    "else:\n",
    "    print(f\"Error: {api_key_file} not found.\")\n",
    "\n",
    "OPENAI_API_KEY = openai.api_key\n",
    "content = \"\"\n",
    "\n",
    "#login to snowflake db\n",
    "\"\"\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='BOOTCAMP_WH',\n",
    "                                 database='SCALE_PLAYPEN',\n",
    "                                 role='SNOWFLAKE_USERS')\n",
    "cs = con.cursor()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List various prompt components\n",
    "Prompt_Beginning = \"You are an expert \"\n",
    "Prompt_Role = \"\"\n",
    "Prompt_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. The questions you ask should be variations of following question:\\n \"\n",
    "Prompt_Human_Question = \"\"\n",
    "Prompt_End = \"\\nUsing the above information, ask a new question about the business. Do not include database terminology. Do not include direct columnn names. Ask question in natural business language. Only respond with question and nothing else, no explanation or other information.\"\n",
    "Prompt_Column_Name = \"\"\n",
    "Prompt_Column_Definition = \"\"\n",
    "Prompt_Complex_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. Some examples of the questions you can ask are listed below\\n \"\n",
    "Prompt_Complex_MidEnd = \"You will now be provided with a few identifier-columns with their definitions and one value-column. Use one or more of identifier columns to build various types of aggregations of the value-column. You can use these aggregations: SUM, AVERAGE, COUNT, MAX, MIN, STANDARD DEVIATION, VARIANCE etc. You can also include as-of-date or day/time in the question\\n\"\n",
    "Prompt_Temperature = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Column_Name                 Column_Definition  \\\n",
      "0                core_level1_code   Asset Type Level 1 - Identifier   \n",
      "1       stat_fx_book_value_amount        Book Value - Dollar Amount   \n",
      "2                 risk_owner_name           Risk Owner - Identifier   \n",
      "3           reinsurance_deal_code     Reinsurance Deal - Identifier   \n",
      "4  security_instrument_identifier  Security Instrument - Identifier   \n",
      "\n",
      "       Used as  \n",
      "0   Identifier  \n",
      "1  Aggregation  \n",
      "2   Identifier  \n",
      "3   Identifier  \n",
      "4   Identifier  \n"
     ]
    }
   ],
   "source": [
    "#Save customer provided questions in a dataframe\n",
    "qdf = pd.read_csv('Customer_Questions.csv')\n",
    "qdf = qdf.dropna()\n",
    "qdf = qdf.reset_index(drop=True)\n",
    "#print(qdf.head())\n",
    "\n",
    "#Save all the used column names with their definitions in a dataframe\n",
    "cdf = pd.read_csv('Column_Definitions.csv')\n",
    "cdf = cdf.dropna()\n",
    "cdf = cdf.reset_index(drop=True)\n",
    "print(cdf.head())\n",
    "\n",
    "#Save various roles in a list called roles\n",
    "roles = ['Financial Analyst', 'Portfolio Manager', 'Risk Manager', 'Trader', 'Executive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Role = np.random.choice(roles)\n",
    "Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "# Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_1 = cdf[cdf['Column_Name'] == Identifier_Column_Name_1]['Column_Definition']\n",
    "Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_2 = cdf[cdf['Column_Name'] == Identifier_Column_Name_2]['Column_Definition']\n",
    "Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_3 = cdf[cdf['Column_Name'] == Identifier_Column_Name_3]['Column_Definition']\n",
    "Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "Aggregation_Column_Definition = cdf[cdf['Column_Name'] == Aggregation_Column_Name]['Column_Definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all necessary functions\n",
    "\n",
    "#make gpt calls\n",
    "def question_gpt(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[{\"role\":\"user\", \"content\":prompt}],\n",
    "        temperature=Prompt_Temperature\n",
    "    )\n",
    "    # Parse the response to get only the \"content\" part and save it in the response variable\n",
    "    response = completion[\"choices\"][0][\"message\"]\n",
    "    return response\n",
    "\n",
    "\n",
    "#combine various prompt elements for a basic prompt\n",
    "def prompt_compiler_basic():\n",
    "    #Choose a random role from list of roles and save it in variable Prompt_Role\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    #Choose a random question from the list of questions in column called 'Question' in qdf dataframe and save it in variable Prompt_Human_Question\n",
    "    Prompt_Human_Question = np.random.choice(qdf['Question'])\n",
    "    #Assign a random value between 0.4 and 0.8 to prompt_temperture variable\n",
    "    Prompt_Temperture = np.random.uniform(0.4,0.8)\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Mid + Prompt_Human_Question + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#combine various prompt elements for a complex prompt\n",
    "def prompt_compiler_complex():\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "    # Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "    Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "    Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_1 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_1, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "        Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_2 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_2, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "        Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_3 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_3, 'Column_Definition'].values[0]\n",
    "    Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "    Aggregation_Column_Definition = cdf.loc[cdf['Column_Name'] == Aggregation_Column_Name, 'Column_Definition'].values[0]\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Complex_Mid + \"\\n\" + Prompt_Human_Question_1 + \"\\n\" + Prompt_Human_Question_2 + \"\\n\" + Prompt_Human_Question_3 + \"\\n\\n\" + Prompt_Complex_MidEnd + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_1 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_1 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_2 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_2 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_3 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_3 + \"\\nAggregation-Column Name:\" + Aggregation_Column_Name + \" Aggregation-Column Definition:\" + Aggregation_Column_Definition +  \"\\n\" + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#create function prompt_cot which takes conversation_history as input and returns a response\n",
    "def prompt_cot(conversation_history):\n",
    "    #compile conversation history\n",
    "    sc_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n1. Did you provide the best response? If yes, then respond 'Yes'. \\nIf no, provide the improved response question and improved response only, nothing else, no apologies needed. Dont say No in response.\"\n",
    "    sc_response = question_gpt(sc_prompt)\n",
    "    complexity_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n2. Was the question asked by you complex enough? If yes, then respond 'Yes'. \\nIf no, provide a question with higher complexity only, nothing else, no apologies needed.\"\n",
    "    complexity_response = question_gpt(complexity_prompt)\n",
    "    return sc_response, complexity_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "what double AA assets do we own?\n",
      "\n",
      "How much exposure do we have to Rail Car assets?\n",
      "\n",
      "Which deals have the best performing yield?\n",
      "\n",
      "What is the notional of CMLs in the Carolina block\n",
      "\n",
      "What asset class has the highest average wal?\n",
      "\n",
      "What is the USD book value of ou non USD assets?\n",
      "\n",
      "what is our current book value by currency?\n",
      "\n",
      "what is the yield trend of the assets retroceded to 3rd parties in past 2 years?\n",
      "\n",
      "what is the breakdown of assets under management by institional business?\n",
      "\n",
      "what is the yield trend of the assets retroceded to 3rd parties in past 2 years?\n",
      "\n",
      "what is the stat book value of the 144a positions we own by legal entity\n",
      "\n",
      "What positions do we have for sec group CRE?\n",
      "\n",
      "What is the proportion of the portfolio by country?\n",
      "\n",
      "How much exposure do we have that is subject to BSCR?\n",
      "\n",
      "What is the average duration by legal entity?\n",
      "\n",
      "What is the open accrued balances by core level 1?\n"
     ]
    }
   ],
   "source": [
    "#use prompt seeding strategy to generate a response\n",
    "Prompt_Modifier = \"\\nModify the question above to retain all of its original intentions and details, but to incorporate modified instructions below. Output just the modified question.\\n\"\n",
    "Prompt_Complexity = \"Increase the complexity in the question Output just the modified prompt.\\n\"\n",
    "Prompt_Diversity = \"Increase the diversity in the question. Output just the modified question.\\n\"\n",
    "Prompt_Structure = \"Restructure the question to make it more natural and human-like. Output just the modified question.\\n\"\n",
    "\n",
    "odf = pd.DataFrame(columns=['Seed_Question', 'Iteration_1', 'Iteration_2', 'Iteration_3'])\n",
    "for i in range(30):\n",
    "    #create an empty df called odf with columns, Seed_question, Iteration_1, Iteration_2, Final_Question\n",
    "    Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "    #save Prompt_Human_Question_1 in Seed_Question column in row i of odf\n",
    "    odf.loc[i, 'Seed_Question'] = Prompt_Human_Question_1\n",
    "    print(\"\\n\" + Prompt_Human_Question_1)\n",
    "    #add another for loop for prompt amplification\n",
    "    for j in range(5):\n",
    "        #if j is odd then call prompt_compiler_complex function\n",
    "        if j % 2 == 1:\n",
    "            response = question_gpt(Prompt_Human_Question_1 + Prompt_Modifier + Prompt_Complexity)\n",
    "        else:\n",
    "            response = question_gpt(Prompt_Human_Question_1 + Prompt_Modifier + Prompt_Diversity)\n",
    "        response = response['content']\n",
    "        #save response in Iteration_+j column in row i of odf\n",
    "        odf.loc[i, 'Iteration_' + str(j+1)] = response\n",
    "print(odf.head())\n",
    "#save odf in a csv file\n",
    "odf.to_csv('Prompt_Amplification.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#call prompt_compiler_complex() function to generate a prompt\n",
    "prompt = prompt_compiler_complex()\n",
    "#call question_gpt() function to generate a response\n",
    "response = question_gpt(prompt)\n",
    "#save json key content from response in response\n",
    "response = response['content']\n",
    "#print(response)\n",
    "conversation_history = \"My question to you:\\n\" + prompt + \"\\n\\n\\nYour response to my question:\" + response\n",
    "print(conversation_history)\n",
    "#call prompt_cot() function to check self-consistency and complexity\n",
    "sc_response, complexity_response = prompt_cot(conversation_history)\n",
    "print(sc_response)\n",
    "print(complexity_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
