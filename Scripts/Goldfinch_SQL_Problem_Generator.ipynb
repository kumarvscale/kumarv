{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\\n                                 account='pxa65918',\\n                                 authenticator='externalbrowser',\\n                                 warehouse='BOOTCAMP_WH',\\n                                 database='SCALE_PLAYPEN',\\n                                 role='SNOWFLAKE_USERS')\\ncs = con.cursor()\\n\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notes\n",
    "# LLM (GPT4) is not good at identifying columns names if provided a SQL query (Test conducted using 100 quesry sample and success rate was 44%)\n",
    "\n",
    "#import libraries\n",
    "import pandas as pd\n",
    "#import snowflake.connector\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Read openai api key from file apikey.txt\n",
    "api_key_file = 'apikey.txt'\n",
    "if os.path.isfile(api_key_file):\n",
    "    with open(api_key_file) as f:\n",
    "        openai.api_key = f.readline()\n",
    "else:\n",
    "    print(f\"Error: {api_key_file} not found.\")\n",
    "\n",
    "OPENAI_API_KEY = openai.api_key\n",
    "content = \"\"\n",
    "\n",
    "#login to snowflake db\n",
    "\"\"\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='BOOTCAMP_WH',\n",
    "                                 database='SCALE_PLAYPEN',\n",
    "                                 role='SNOWFLAKE_USERS')\n",
    "cs = con.cursor()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List various prompt components\n",
    "Prompt_Beginning = \"You are an expert \"\n",
    "Prompt_Role = \"\"\n",
    "Prompt_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. The questions you ask should be variations of following question:\\n \"\n",
    "Prompt_Human_Question = \"\"\n",
    "Prompt_End = \"\\nUsing the above information, ask a new question about the business. Do not include database terminology. Do not include direct columnn names. Ask question in natural business language. Only respond with question and nothing else, no explanation or other information.\"\n",
    "Prompt_Column_Name = \"\"\n",
    "Prompt_Column_Definition = \"\"\n",
    "Prompt_Complex_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. Some examples of the questions you can ask are listed below\\n \"\n",
    "Prompt_Complex_MidEnd = \"You will now be provided with a few identifier-columns with their definitions and one value-column. Use one or more of identifier columns to build various types of aggregations of the value-column. You can use these aggregations: SUM, AVERAGE, COUNT, MAX, MIN, STANDARD DEVIATION, VARIANCE etc. You can also include as-of-date or day/time in the question\\n\"\n",
    "Prompt_Temperature = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Column_Name                 Column_Definition  \\\n",
      "0                core_level1_code   Asset Type Level 1 - Identifier   \n",
      "1       stat_fx_book_value_amount        Book Value - Dollar Amount   \n",
      "2                 risk_owner_name           Risk Owner - Identifier   \n",
      "3           reinsurance_deal_code     Reinsurance Deal - Identifier   \n",
      "4  security_instrument_identifier  Security Instrument - Identifier   \n",
      "\n",
      "       Used as  \n",
      "0   Identifier  \n",
      "1  Aggregation  \n",
      "2   Identifier  \n",
      "3   Identifier  \n",
      "4   Identifier  \n"
     ]
    }
   ],
   "source": [
    "#Save customer provided questions in a dataframe\n",
    "qdf = pd.read_csv('Customer_Questions.csv')\n",
    "qdf = qdf.dropna()\n",
    "qdf = qdf.reset_index(drop=True)\n",
    "#print(qdf.head())\n",
    "\n",
    "#Save all the used column names with their definitions in a dataframe\n",
    "cdf = pd.read_csv('Column_Definitions.csv')\n",
    "cdf = cdf.dropna()\n",
    "cdf = cdf.reset_index(drop=True)\n",
    "print(cdf.head())\n",
    "\n",
    "#Save various roles in a list called roles\n",
    "roles = ['Financial Analyst', 'Portfolio Manager', 'Risk Manager', 'Trader', 'Executive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Role = np.random.choice(roles)\n",
    "Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "# Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_1 = cdf[cdf['Column_Name'] == Identifier_Column_Name_1]['Column_Definition']\n",
    "Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_2 = cdf[cdf['Column_Name'] == Identifier_Column_Name_2]['Column_Definition']\n",
    "Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_3 = cdf[cdf['Column_Name'] == Identifier_Column_Name_3]['Column_Definition']\n",
    "Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "Aggregation_Column_Definition = cdf[cdf['Column_Name'] == Aggregation_Column_Name]['Column_Definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all necessary functions\n",
    "\n",
    "#make gpt calls\n",
    "def question_gpt(prompt):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4-1106-preview\",\n",
    "        messages=[{\"role\":\"user\", \"content\":prompt}],\n",
    "        temperature=Prompt_Temperature\n",
    "    )\n",
    "    # Parse the response to get only the \"content\" part and save it in the response variable\n",
    "    response = completion[\"choices\"][0][\"message\"]\n",
    "    return response\n",
    "\n",
    "\n",
    "#combine various prompt elements for a basic prompt\n",
    "def prompt_compiler_basic():\n",
    "    #Choose a random role from list of roles and save it in variable Prompt_Role\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    #Choose a random question from the list of questions in column called 'Question' in qdf dataframe and save it in variable Prompt_Human_Question\n",
    "    Prompt_Human_Question = np.random.choice(qdf['Question'])\n",
    "    #Assign a random value between 0.4 and 0.8 to prompt_temperture variable\n",
    "    Prompt_Temperture = np.random.uniform(0.4,0.8)\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Mid + Prompt_Human_Question + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#combine various prompt elements for a complex prompt\n",
    "def prompt_compiler_complex():\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "    # Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "    Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "    Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_1 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_1, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "        Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_2 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_2, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "        Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_3 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_3, 'Column_Definition'].values[0]\n",
    "    Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "    Aggregation_Column_Definition = cdf.loc[cdf['Column_Name'] == Aggregation_Column_Name, 'Column_Definition'].values[0]\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Complex_Mid + \"\\n\" + Prompt_Human_Question_1 + \"\\n\" + Prompt_Human_Question_2 + \"\\n\" + Prompt_Human_Question_3 + \"\\n\\n\" + Prompt_Complex_MidEnd + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_1 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_1 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_2 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_2 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_3 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_3 + \"\\nAggregation-Column Name:\" + Aggregation_Column_Name + \" Aggregation-Column Definition:\" + Aggregation_Column_Definition +  \"\\n\" + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#create function prompt_cot which takes conversation_history as input and returns a response\n",
    "def prompt_cot(conversation_history):\n",
    "    #compile conversation history\n",
    "    sc_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n1. Did you provide the best response? If yes, then respond 'Yes'. \\nIf no, provide the improved response question and improved response only, nothing else, no apologies needed. Dont say No in response.\"\n",
    "    sc_response = question_gpt(sc_prompt)\n",
    "    complexity_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n2. Was the question asked by you complex enough? If yes, then respond 'Yes'. \\nIf no, provide a question with higher complexity only, nothing else, no apologies needed.\"\n",
    "    complexity_response = question_gpt(complexity_prompt)\n",
    "    return sc_response, complexity_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My question to you:\n",
      "You are an expert Financial Analyst. You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. Some examples of the questions you can ask are listed below\n",
      " \n",
      "how many distinct assets are rated by Egan Jones?\n",
      "How has the average book yield changed YTD by Asset class?\n",
      "Which deals have the best performing yield?\n",
      "\n",
      "You will now be provided with a few identifier-columns with their definitions and one value-column. Use one or more of identifier columns to build various types of aggregations of the value-column. You can use these aggregations: SUM, AVERAGE, COUNT, MAX, MIN, STANDARD DEVIATION, VARIANCE etc. You can also include as-of-date or day/time in the question\n",
      "\n",
      "Identifier-Column Name:security_instrument_identifier Identifier-Column Definition:Security Instrument - Identifier\n",
      "Identifier-Column Name:portfolio_identifier Identifier-Column Definition:Portfolio - Identifier\n",
      "Identifier-Column Name:naic_designation_code Identifier-Column Definition:NAIC Designation - Identifier\n",
      "Aggregation-Column Name:zero_volatility_spread_amount Aggregation-Column Definition:Zero Volatility Spread - Dollar Amount\n",
      "\n",
      "Using the above information, ask a new question about the business. Do not include database terminology and ask question in natural business language. Only respond with question and nothing else, no explanation or other information.\n",
      "\n",
      "\n",
      "Your response to my question:What is the average zero volatility spread amount for each NAIC designation code within our portfolio?\n",
      "{\n",
      "  \"content\": \"What is the sum of zero volatility spread amounts for securities rated by Egan Jones across all portfolios?\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n",
      "{\n",
      "  \"content\": \"Yes.\",\n",
      "  \"role\": \"assistant\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#call prompt_compiler_complex() function to generate a prompt\n",
    "prompt = prompt_compiler_complex()\n",
    "#call question_gpt() function to generate a response\n",
    "response = question_gpt(prompt)\n",
    "#save json key content from response in response\n",
    "response = response['content']\n",
    "#print(response)\n",
    "conversation_history = \"My question to you:\\n\" + prompt + \"\\n\\n\\nYour response to my question:\" + response\n",
    "print(conversation_history)\n",
    "#call prompt_cot() function to check self-consistency and complexity\n",
    "sc_response, complexity_response = prompt_cot(conversation_history)\n",
    "print(sc_response)\n",
    "print(complexity_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
