{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\\n                                 account='pxa65918',\\n                                 authenticator='externalbrowser',\\n                                 warehouse='BOOTCAMP_WH',\\n                                 database='SCALE_PLAYPEN',\\n                                 role='SNOWFLAKE_USERS')\\ncs = con.cursor()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import libraries\n",
    "import pandas as pd\n",
    "#import snowflake.connector\n",
    "import numpy as np\n",
    "import openai\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Read openai api key from file apikey.txt\n",
    "api_key_file = 'apikey-gemini.txt'\n",
    "if os.path.isfile(api_key_file):\n",
    "    with open(api_key_file) as f:\n",
    "        GOOGLE_API_KEY = f.readline()\n",
    "else:\n",
    "    print(f\"Error: {api_key_file} not found.\")\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "OPENAI_API_KEY = openai.api_key\n",
    "content = \"\"\n",
    "\n",
    "#login to snowflake db\n",
    "\"\"\"con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='BOOTCAMP_WH',\n",
    "                                 database='SCALE_PLAYPEN',\n",
    "                                 role='SNOWFLAKE_USERS')\n",
    "cs = con.cursor()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List various prompt components\n",
    "Prompt_Beginning = \"You are an expert \"\n",
    "Prompt_Role = \"\"\n",
    "Prompt_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. The questions you ask should be variations of following question:\\n \"\n",
    "Prompt_Human_Question = \"\"\n",
    "Prompt_End = \"\\nUsing the above information, ask a new question about the business. Do not include database terminology. Do not include direct columnn names. Ask question in natural business language. Only respond with question and nothing else, no explanation or other information.\"\n",
    "Prompt_Column_Name = \"\"\n",
    "Prompt_Column_Definition = \"\"\n",
    "Prompt_Complex_Mid = \". You are tasked with asking relevant questions about various assets, trade positions and holdings of the business. Some examples of the questions you can ask are listed below\\n \"\n",
    "Prompt_Complex_MidEnd = \"You will now be provided with a few identifier-columns with their definitions and one value-column. Use one or more of identifier columns to build various types of aggregations of the value-column. You can use these aggregations: SUM, AVERAGE, COUNT, MAX, MIN, STANDARD DEVIATION, VARIANCE etc. You can also include as-of-date or day/time in the question\\n\"\n",
    "Prompt_Temperature = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save customer provided questions in a dataframe\n",
    "qdf = pd.read_csv('Customer_Questions.csv')\n",
    "qdf = qdf.dropna()\n",
    "qdf = qdf.reset_index(drop=True)\n",
    "#print(qdf.head())\n",
    "\n",
    "#Save all the used column names with their definitions in a dataframe\n",
    "cdf = pd.read_csv('Column_Definitions.csv')\n",
    "cdf = cdf.dropna()\n",
    "cdf = cdf.reset_index(drop=True)\n",
    "#print(cdf.head())\n",
    "\n",
    "#Save various roles in a list called roles\n",
    "roles = ['Financial Analyst', 'Portfolio Manager', 'Risk Manager', 'Trader', 'Executive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt_Role = np.random.choice(roles)\n",
    "Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "# Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_1 = cdf[cdf['Column_Name'] == Identifier_Column_Name_1]['Column_Definition']\n",
    "Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_2 = cdf[cdf['Column_Name'] == Identifier_Column_Name_2]['Column_Definition']\n",
    "Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "Identifier_Column_Definition_3 = cdf[cdf['Column_Name'] == Identifier_Column_Name_3]['Column_Definition']\n",
    "Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "Aggregation_Column_Definition = cdf[cdf['Column_Name'] == Aggregation_Column_Name]['Column_Definition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much revenue is projected to come from each product line in the next quarter?\n"
     ]
    }
   ],
   "source": [
    "prompt = Prompt_Beginning + Prompt_Role + Prompt_Mid + Prompt_Human_Question + Prompt_End\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "response = model.generate_content(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create all necessary functions\n",
    "\n",
    "#make gpt calls\n",
    "def question_gemini(prompt):\n",
    "    model = genai.GenerativeModel('gemini-pro')\n",
    "    model.generate_content(prompt)\n",
    "    response = response.text\n",
    "    return response\n",
    "\n",
    "def to_markdown(text):\n",
    "  text = text.replace('â€¢', '  *')\n",
    "  return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n",
    "\n",
    "\n",
    "#combine various prompt elements for a basic prompt\n",
    "def prompt_compiler_basic():\n",
    "    #Choose a random role from list of roles and save it in variable Prompt_Role\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    #Choose a random question from the list of questions in column called 'Question' in qdf dataframe and save it in variable Prompt_Human_Question\n",
    "    Prompt_Human_Question = np.random.choice(qdf['Question'])\n",
    "    #Assign a random value between 0.4 and 0.8 to prompt_temperture variable\n",
    "    Prompt_Temperture = np.random.uniform(0.4,0.8)\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Mid + Prompt_Human_Question + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#combine various prompt elements for a complex prompt\n",
    "def prompt_compiler_complex():\n",
    "    Prompt_Role = np.random.choice(roles)\n",
    "    Prompt_Human_Question_1 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_2 = np.random.choice(qdf['Question'])\n",
    "    Prompt_Human_Question_3 = np.random.choice(qdf['Question'])\n",
    "    # Assign a random value between 0.1 and 0.4 to prompt_temperature variable\n",
    "    Prompt_Temperature = np.random.uniform(0.1, 0.4)\n",
    "    Identifier_Column_Name_1 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_1 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_1, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_2:\n",
    "        Identifier_Column_Name_2 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_2 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_2, 'Column_Definition'].values[0]\n",
    "    Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    if Identifier_Column_Name_1 == Identifier_Column_Name_3 or Identifier_Column_Name_2 == Identifier_Column_Name_3:\n",
    "        Identifier_Column_Name_3 = np.random.choice(cdf[cdf['Used as'] == 'Identifier']['Column_Name'])\n",
    "    Identifier_Column_Definition_3 = cdf.loc[cdf['Column_Name'] == Identifier_Column_Name_3, 'Column_Definition'].values[0]\n",
    "    Aggregation_Column_Name = np.random.choice(cdf[cdf['Used as'] == 'Aggregation']['Column_Name'])\n",
    "    Aggregation_Column_Definition = cdf.loc[cdf['Column_Name'] == Aggregation_Column_Name, 'Column_Definition'].values[0]\n",
    "    prompt = Prompt_Beginning + Prompt_Role + Prompt_Complex_Mid + \"\\n\" + Prompt_Human_Question_1 + \"\\n\" + Prompt_Human_Question_2 + \"\\n\" + Prompt_Human_Question_3 + \"\\n\\n\" + Prompt_Complex_MidEnd + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_1 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_1 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_2 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_2 + \"\\nIdentifier-Column Name:\" + Identifier_Column_Name_3 + \" Identifier-Column Definition:\" + Identifier_Column_Definition_3 + \"\\nAggregation-Column Name:\" + Aggregation_Column_Name + \" Aggregation-Column Definition:\" + Aggregation_Column_Definition +  \"\\n\" + Prompt_End\n",
    "    return prompt\n",
    "\n",
    "#create function prompt_cot which takes conversation_history as input and returns a response\n",
    "def prompt_cot(conversation_history):\n",
    "    #compile conversation history\n",
    "    sc_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n1. Did you provide the best response? If yes, then respond 'Yes'. \\nIf no, provide the improved response question and improved response only, nothing else, no apologies needed. Dont say No in response.\"\n",
    "    sc_response = question_gemini(sc_prompt)\n",
    "    complexity_prompt = \"Read our conversation history provided below and answer the following questions:\\n\" + conversation_history + \"\\n2. Was the question asked by you complex enough? If yes, then respond 'Yes'. \\nIf no, provide a question with higher complexity only, nothing else, no apologies needed.\"\n",
    "    complexity_response = question_gemini(complexity_prompt)\n",
    "    return sc_response, complexity_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'response' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb Cell 7\u001b[0m line \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     response \u001b[39m=\u001b[39m question_gemini(Prompt_Human_Question_1 \u001b[39m+\u001b[39m Prompt_Modifier \u001b[39m+\u001b[39m Prompt_Complexity)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     response \u001b[39m=\u001b[39m question_gemini(Prompt_Human_Question_1 \u001b[39m+\u001b[39;49m Prompt_Modifier \u001b[39m+\u001b[39;49m Prompt_Diversity)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m response \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39m#save response in Iteration_+j column in row i of odf\u001b[39;00m\n",
      "\u001b[1;32m/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb Cell 7\u001b[0m line \u001b[0;36mquestion_gemini\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m model \u001b[39m=\u001b[39m genai\u001b[39m.\u001b[39mGenerativeModel(\u001b[39m'\u001b[39m\u001b[39mgemini-pro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39mgenerate_content(prompt)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m response \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mtext\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/vishalkumar/Documents/Git-Repo/kumarv/Scripts/Goldfinch_SQL_Problem_Generator_Gemini_v2.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'response' referenced before assignment"
     ]
    }
   ],
   "source": [
    "#use prompt seeding strategy to generate a response\n",
    "Prompt_Modifier = \"\\nModify the question above to retain all of its original intentions and details, but to incorporate modified instructions below. Output just the modified question.\\n\"\n",
    "Prompt_Complexity = \"Increase the complexity in the question Output just the modified prompt.\\n\"\n",
    "Prompt_Diversity = \"Increase the diversity in the question. Output just the modified question.\\n\"\n",
    "Prompt_Structure = \"Restructure the question to make it more natural and human-like. Output just the modified question.\\n\"\n",
    "\n",
    "odf = pd.DataFrame(columns=['Seed_Question', 'Iteration_1', 'Iteration_2', 'Iteration_3'])\n",
    "for i in tqdm(range(25)):\n",
    "    #pick the current row question from qdf and save it in Prompt_Human_Question_1\n",
    "    Prompt_Human_Question_1 = qdf.loc[i, 'Question']\n",
    "    #save Prompt_Human_Question_1 in Seed_Question column in row i of odf\n",
    "    odf.loc[i, 'Seed_Question'] = Prompt_Human_Question_1\n",
    "    #print(\"\\n\" + Prompt_Human_Question_1)\n",
    "    #add another for loop for prompt amplification\n",
    "    for j in range(5):\n",
    "        #if j is odd then call prompt_compiler_complex function\n",
    "        if j % 2 == 1:\n",
    "            response = question_gemini(Prompt_Human_Question_1 + Prompt_Modifier + Prompt_Complexity)\n",
    "        else:\n",
    "            response = question_gemini(Prompt_Human_Question_1 + Prompt_Modifier + Prompt_Diversity)\n",
    "        response = response['content']\n",
    "        #save response in Iteration_+j column in row i of odf\n",
    "        odf.loc[i, 'Iteration_' + str(j+1)] = response\n",
    "#print(odf.head())\n",
    "#save odf in a csv file\n",
    "odf.to_csv('Prompt_Amplification_Output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an emptydf called odf with columns conversation_history, sc_response, complexity_response\n",
    "\n",
    "#add a for loop with tqdm for 30 iterations\n",
    "for i in tqdm(range(30)):\n",
    "    prompt = prompt_compiler_complex()\n",
    "    response = question_gemini(prompt)\n",
    "    #save json key content from response in response\n",
    "    response = response['content']\n",
    "    conversation_history = \"My question to you:\\n\" + prompt + \"\\n\\n\\nYour response to my question:\" + response\n",
    "    sc_response, complexity_response = prompt_cot(conversation_history)\n",
    "    #save conversation_history, sc_response, complexity_response in odf\n",
    "    odf.loc[i, 'conversation_history'] = conversation_history\n",
    "    odf.loc[i, 'sc_response'] = sc_response\n",
    "    odf.loc[i, 'complexity_response'] = complexity_response\n",
    "\n",
    "#save odf in a csv file\n",
    "odf.to_csv('Prompt_Randomization_Output.csv')\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
