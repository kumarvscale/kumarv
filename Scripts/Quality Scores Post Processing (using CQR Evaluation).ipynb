{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2547e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import datetime\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "import os\n",
    "import os.path\n",
    "import snowflake.connector\n",
    "import boto3\n",
    "from __future__ import print_function\n",
    "from google.auth.transport.requests import Request\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49233096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3\n",
    "BUCKET = 'scale-crawler-enriched-csv-exports-us-west-2'\n",
    "s3 = boto3.client('s3')\n",
    "session = boto3.Session()\n",
    "\n",
    "# Google Sheets\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "SPREADSHEET_ID = '1ycZEbsg7hEb_kKAYmIg6eK0hBIl4fvhK0FDan1f5UkE'\n",
    "RANGE_NAME = 'Sheet9!A:M'\n",
    "PATH_TO_SECRETS_FILE = 'credentials.json'\n",
    "creds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1e111ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating login request with your identity provider. A browser window should have opened for you to complete the login. If you can't see it, check existing browser windows, or your OS settings. Press CTRL+C to abort and try again...\n"
     ]
    }
   ],
   "source": [
    "#Snowflake\n",
    "con = snowflake.connector.connect(user='vishal.kumar@scale.com',\n",
    "                                 account='pxa65918',\n",
    "                                 authenticator='externalbrowser',\n",
    "                                 warehouse='COMPUTE_WH',\n",
    "                                 database='SCALE_CRAWLER',\n",
    "                                 role='GENERAL_RO')\n",
    "cs = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376abd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def uploadData(data,filename):\n",
    "    s3.put_object(\n",
    "        ACL='bucket-owner-full-control',\n",
    "        Body=data.encode('utf-8'),\n",
    "        Bucket=RESULTS_BUCKET,\n",
    "        Key=f'flamingo_qa_potential_issues/{filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71383a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Pull data from Google Sheet https://docs.google.com/spreadsheets/d/1UCIE1P6PbI9odzxFUjNF44s-SaPePbDUnHQKqxa9XpM/edit#gid=774020952\n",
    "def pullFromGS(SCOPES,PATH_TO_SECRETS_FILE,creds,SPREADSHEET_ID,RANGE_NAME):\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json', SCOPES)\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(PATH_TO_SECRETS_FILE, SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    try:\n",
    "        service = build('sheets', 'v4', credentials=creds)\n",
    "\n",
    "        sheet = service.spreadsheets()\n",
    "        result = sheet.values().get(spreadsheetId=SPREADSHEET_ID,range=RANGE_NAME).execute()\n",
    "        values = result.get('values', [])\n",
    "\n",
    "        if not values:\n",
    "            print('No data found.')\n",
    "        \n",
    "    except HttpError as err:\n",
    "        print(err)\n",
    "        \n",
    "    df = pd.DataFrame(values[1:],columns = values[0])    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b9c14ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All CQR audit data from Spotter Audits including S3 csv path which contains each PVID and its attributes with results\n",
    "def getCQRResults(min_date,max_date):\n",
    "    \n",
    "    sql = f'''\n",
    "    with cqr_result as (\n",
    "      with audits as (\n",
    "        select\n",
    "          sa.CATALOG_ID,\n",
    "          sa.domain,\n",
    "          sa.BODY_S3_KEY,\n",
    "          sa._id audit_id,\n",
    "          date(sa.completed_at) audit_time,\n",
    "          sa.grade :\"scores\" :\"descriptionScore\" :\"score\" as CQR_DESCRIPTION_SCORE,\n",
    "          sa.grade :\"scores\" :\"titleScore\" :\"score\" as Title,\n",
    "          sa.result\n",
    "        from\n",
    "          PUBLIC.SPOTTERAUDITS sa\n",
    "          inner join (\n",
    "            select\n",
    "              max(completed_at) as max_time,\n",
    "              CATALOG_ID\n",
    "            from\n",
    "              PUBLIC.SPOTTERAUDITS\n",
    "            group by\n",
    "              CATALOG_ID\n",
    "          ) as cqr_max on cqr_max.CATALOG_ID = sa.CATALOG_ID\n",
    "          and cqr_max.max_time = sa.completed_at\n",
    "        where\n",
    "          AUDIT_TYPE = 'Attributes'\n",
    "          and sa.COMPLETED_AT is not null\n",
    "          and sa.grade :\"scores\" :\"descriptionScore\" :\"score\" is not null\n",
    "          and date(sa.completed_at) >= '{min_date}'\n",
    "          and date(sa.completed_at) <= '{max_date}'\n",
    "      )\n",
    "      select\n",
    "        au.CATALOG_ID,\n",
    "        au.domain,\n",
    "        au.audit_id,\n",
    "        au.audit_time CQR_AUDIT_DATE,\n",
    "        au.BODY_S3_KEY,\n",
    "        a.key variant_id,\n",
    "        b.key attribute,\n",
    "        b.value :result :: string attribute_grade,\n",
    "        b.value :reason :: string reason,\n",
    "        b.value :comment :: string comment  \n",
    "      from\n",
    "        audits au,\n",
    "        lateral flatten (input => au.result) a,\n",
    "        lateral flatten (input => a.value) b\n",
    "      where\n",
    "        b.key in ('description')\n",
    "        and b.value :result = 'Incorrect'\n",
    "    )\n",
    "    select \n",
    "    c.*,\n",
    "    pv.pvid,\n",
    "    pv.scraped_attributes:link::string link\n",
    "    from cqr_result c\n",
    "    join productvariants pv on pv.unique_id = c.variant_id\n",
    "    '''\n",
    "    print('Getting CQR incorrect results from Snowflake!')\n",
    "    cs.execute(sql)\n",
    "    df = cs.fetch_pandas_all()\n",
    "    print('Success! Got CQR incorrect results from Snowflake. Number of rows:',len(df),'\\n-------------')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0d9a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "#All CQR audit data from Spotter Audits including S3 csv path which contains each PVID and its attributes with results\n",
    "def getCQRCount(min_date,max_date):\n",
    "    \n",
    "    sql = f'''\n",
    "    with cqr_result as (\n",
    "      with audits as (\n",
    "        select\n",
    "          sa.CATALOG_ID,\n",
    "          sa.domain,\n",
    "          sa.BODY_S3_KEY,\n",
    "          sa._id audit_id,\n",
    "          date(sa.completed_at) audit_time,\n",
    "          sa.grade :\"scores\" :\"descriptionScore\" :\"score\" as CQR_DESCRIPTION_SCORE,\n",
    "          sa.grade :\"scores\" :\"titleScore\" :\"score\" as Title,\n",
    "          sa.result\n",
    "        from\n",
    "          PUBLIC.SPOTTERAUDITS sa\n",
    "          inner join (\n",
    "            select\n",
    "              max(completed_at) as max_time,\n",
    "              CATALOG_ID\n",
    "            from\n",
    "              PUBLIC.SPOTTERAUDITS\n",
    "            group by\n",
    "              CATALOG_ID\n",
    "          ) as cqr_max on cqr_max.CATALOG_ID = sa.CATALOG_ID\n",
    "          and cqr_max.max_time = sa.completed_at\n",
    "        where\n",
    "          AUDIT_TYPE = 'Attributes'\n",
    "          and sa.COMPLETED_AT is not null\n",
    "          and sa.grade :\"scores\" :\"descriptionScore\" :\"score\" is not null\n",
    "          and date(sa.completed_at) >= '{min_date}'\n",
    "          and date(sa.completed_at) <= '{max_date}'\n",
    "      )\n",
    "      select\n",
    "        au.CATALOG_ID,\n",
    "        au.domain,\n",
    "        au.audit_id,\n",
    "        au.audit_time CQR_AUDIT_DATE,\n",
    "        au.BODY_S3_KEY,\n",
    "        a.key variant_id,\n",
    "        b.key attribute,\n",
    "        b.value :result :: string attribute_grade,\n",
    "        b.value :reason :: string reason,\n",
    "        b.value :comment :: string comment  \n",
    "      from\n",
    "        audits au,\n",
    "        lateral flatten (input => au.result) a,\n",
    "        lateral flatten (input => a.value) b\n",
    "      where\n",
    "        b.key in ('description')\n",
    "    )\n",
    "    select \n",
    "    c.*,\n",
    "    pv.pvid,\n",
    "    pv.scraped_attributes:link::string link\n",
    "    from cqr_result c\n",
    "    join productvariants pv on pv.unique_id = c.variant_id\n",
    "    '''\n",
    "    print('Getting all CQR data from Snowflake!')\n",
    "    cs.execute(sql)\n",
    "    df = cs.fetch_pandas_all()\n",
    "    print('Success! Got all CQR data from Snowflake. Number of rows:',len(df),'\\n-------------')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7d0db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the column S3 csv url and consolidate all audits csv data into one dataframe, return this df\n",
    "def getCQRInputs(cqr_results):\n",
    "    \n",
    "    df = pd.DataFrame() \n",
    "    print('Getting CQR input data from S3!')\n",
    "    for s3_file in cqr_results['BODY_S3_KEY'].unique().tolist():\n",
    "        print('Pulling from', s3_file)\n",
    "        response = s3.get_object(Bucket = BUCKET, Key = s3_file)\n",
    "        tmp = pd.read_csv(response.get(\"Body\"))\n",
    "        df = pd.concat([df,tmp])\n",
    "    print('Success! Got CQR input data from S3. Number of rows:', len(df),'\\n-------------')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c10c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge audit data with PVID attributes data and flags\n",
    "def mergeCQRData(cqr_results, cqr_inputs):\n",
    "    if len(cqr_results) == 0 or len(cqr_inputs) == 0: \n",
    "        print('ERROR: Not enough information to complete')\n",
    "        df = pd.DataFrame()\n",
    "    else:\n",
    "        print('Merging data!')\n",
    "        df = cqr_results.merge(cqr_inputs[['pvid','description','link']], left_on = 'PVID', right_on = 'pvid')\n",
    "        df = df.fillna('').rename(columns = {'description':'POST_PROCESSED_DESCRIPTION','COMMENT':'CORRECT_DESCRIPTION'})\n",
    "\n",
    "        df = df.sort_values(['POST_PROCESSED_DESCRIPTION'])\n",
    "        df = df.loc[(df['POST_PROCESSED_DESCRIPTION'] != '') & (df['CORRECT_DESCRIPTION'] != '')] \n",
    "        print('Success! Merged data. Number of rows:', len(df),'\\n-------------')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9a44413",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get QA events data - post processing task logs by QA, by PVID\n",
    "def getPPQAData(relevant_pvids):\n",
    "    pvids = \"('\" + \"','\".join(relevant_pvids) + \"')\"\n",
    "#     print(pvids)\n",
    "    sql_descs = f'''\n",
    "    select\n",
    "      user_email,\n",
    "      _ID,\n",
    "      metadata :pvids description_id,\n",
    "      b.value :: string pvid,\n",
    "      CREATED_AT variant_pped_at,\n",
    "      metadata: auditLevel :: string audit_level,\n",
    "      metadata: fieldCurrent :: string QA_DESCRIPTION\n",
    "    from\n",
    "      PUBLIC.QAEVENTS,\n",
    "      lateral flatten(input => metadata :pvids) b\n",
    "    where\n",
    "      audit_level != 'Other'\n",
    "      and METADATA :action in ('Save', 'SwitchItem')\n",
    "      and metadata: fieldCurrent is not Null\n",
    "      and pvid in {pvids}\n",
    "    '''\n",
    "\n",
    "    sql_rules = f'''\n",
    "    select\n",
    "      user_email,\n",
    "      metadata :pvids description_id,\n",
    "      b.value :: string pvid,\n",
    "      CREATED_AT variant_pped_at,\n",
    "      metadata: auditLevel :: string audit_level,\n",
    "      metadata: flagComment :: string flagtext,\n",
    "      metadata: ruleCreated :: string ruleCreated\n",
    "    from\n",
    "      PUBLIC.QAEVENTS,\n",
    "      lateral flatten(input => metadata :pvids) b\n",
    "    where\n",
    "      audit_level != 'Other'\n",
    "      and METADATA :action in ('CreateRule')\n",
    "      and metadata: flagComment is not Null\n",
    "      and pvid in {pvids}\n",
    "    '''\n",
    "    \n",
    "\n",
    "    \n",
    "    print('Getting descriptions data from Snowflake!')\n",
    "    cs.execute(sql_descs)\n",
    "    pp_desc_data = cs.fetch_pandas_all()\n",
    "    print('Success! Got descriptions data from Snowflake. Number of rows:',len(pp_desc_data))    \n",
    "    \n",
    "    print('Getting rules data from Snowflake!')\n",
    "    cs.execute(sql_rules)\n",
    "    pp_rules_data = cs.fetch_pandas_all()\n",
    "    print('Success! Got rules data from Snowflake. Number of rows:',len(pp_rules_data),'\\n-------------')    \n",
    "    \n",
    "    return pp_desc_data, pp_rules_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9574fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine CQR audit data with PP QA Events and find 'extra' or 'missing' text in the description - FOR SPEED AUDITS\n",
    "def generateSpeedAuditErrors(cqr_data, pp_desc_data):\n",
    "    cols = ['CQR_AUDIT_DATE', 'USER_EMAIL', 'type', 'AUDIT_LEVEL',\n",
    "                    'DOMAIN', 'description_PPed_at', 'sample_pvid',\n",
    "                    'sample_link','CORRECT_DESCRIPTION', 'QA_DESCRIPTION',\n",
    "                   'Extra text (not removed by QA)',\n",
    "                   'Missing text (incorrectly removed by QA)','outcome']\n",
    "        \n",
    "    if len(cqr_data) == 0 or len(pp_desc_data) == 0: \n",
    "        print('ERROR: Not enough information to complete')\n",
    "        dff = pd.DataFrame(columns = cols)\n",
    "    else: \n",
    "        print('Generating Speed Audit errors!')\n",
    "        df = cqr_data.merge(pp_desc_data, on = 'PVID')\n",
    "        df = df.rename(columns = {'COMMENT':'CORRECT_DESCRIPTION'})\n",
    "        df['clean_final_desc'] = df.apply(lambda x: re.sub('\\\\\\\\n|\\n| ','',x['CORRECT_DESCRIPTION']),axis=1)\n",
    "        df['clean_fieldcurrent'] = df.apply(lambda x: re.sub('\\\\\\\\n|\\n| ','',x['QA_DESCRIPTION']),axis=1)\n",
    "        df['is_correct_desc'] = df['clean_final_desc'] == df['clean_fieldcurrent']\n",
    "        df = df.drop_duplicates() # .loc[df['is_correct_desc'] == False]\n",
    "        if len(df) ==0:\n",
    "            return df\n",
    "        else:\n",
    "            tmp_cols = ['CQR_AUDIT_DATE',\n",
    "                'USER_EMAIL',\n",
    "                'AUDIT_LEVEL',\n",
    "                'DOMAIN',\n",
    "                'CORRECT_DESCRIPTION',\n",
    "                'QA_DESCRIPTION','is_correct_desc']\n",
    "\n",
    "            dff = df.groupby(tmp_cols)['VARIANT_PPED_AT','PVID','LINK'].min()                .reset_index()                .rename(columns = {'VARIANT_PPED_AT':'description_PPed_at','PVID':'sample_pvid','LINK':'sample_link'})\n",
    "            dff['Extra text (not removed by QA)'] = dff.apply(lambda x: np.setdiff1d([i.strip('. ').strip('! ').strip('? ').lower() for i in re.split('\\. |\\n|\\! |\\? ', x['QA_DESCRIPTION']) if i != ''],[i.strip('. ').strip('! ').strip('? ').lower() for i in re.split('\\. |\\n|\\! |\\? ', x['CORRECT_DESCRIPTION']) if i != '']), axis = 1)    \n",
    "            dff['Missing text (incorrectly removed by QA)'] = dff.apply(lambda x: np.setdiff1d([i.strip('. ').strip('! ').strip('? ').lower() for i in re.split('\\. |\\n|\\! |\\? ', x['CORRECT_DESCRIPTION']) if i != ''],[i.strip('. ').strip('! ').strip('? ').lower() for i in re.split('\\. |\\n|\\! |\\? ', x['QA_DESCRIPTION']) if i != '']), axis = 1)\n",
    "            dff['type'] = 'Speed Audit'\n",
    "            dff['outcome'] = dff.apply(lambda x: 'incorrect speed audit' if x['is_correct_desc'] == False else 'correct speed audit', axis = 1)\n",
    "            dfg = df.groupby(['USER_EMAIL'])['PVID'].nunique() \n",
    "            print('Success! Generated Speed Audit Errors\\n-------------')     \n",
    "        return dfg, dff.loc[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61bb94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get total sample of CQR Audits\n",
    "def generateAuditCountQA(cqr_count, pp_desc_data):\n",
    "    cols = ['CQR_AUDIT_DATE', 'USER_EMAIL', 'type', 'AUDIT_LEVEL',\n",
    "                    'DOMAIN', 'description_PPed_at', 'sample_pvid',\n",
    "                    'sample_link','CORRECT_DESCRIPTION', 'QA_DESCRIPTION',\n",
    "                   'Extra text (not removed by QA)',\n",
    "                   'Missing text (incorrectly removed by QA)','outcome']\n",
    "        \n",
    "    if len(cqr_count) == 0 or len(pp_desc_data) == 0: \n",
    "        print('ERROR: Not enough information to complete')\n",
    "        dff = pd.DataFrame(columns = cols)\n",
    "    else: \n",
    "        print('Generating QA Sample Size Count')\n",
    "        df = cqr_count.merge(pp_desc_data, how='left', on = 'fb_product_id')\n",
    "        df = df.rename(columns = {'COMMENT':'CORRECT_DESCRIPTION'})\n",
    "        dff = df.groupby(['USER_EMAIL'])['fb_product_id'].nunique() \n",
    "        print('Success! QA Sample Size Count')     \n",
    "        return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e551fe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Combine CQR audit data with PP QA Events and find 'extra' or 'missing' text in the description - FOR FLAG AUDITS\n",
    "def generateFlagAuditErrors(full_cqr_data, pp_rules_data):\n",
    "    cols = ['CQR_AUDIT_DATE', 'USER_EMAIL','type','AUDIT_LEVEL',\n",
    "                'DOMAIN', 'description_PPed_at', 'sample_pvid',\n",
    "                'sample_link','FLAGTEXT', 'RULECREATED',\n",
    "               'Extra text (not removed by QA)',\n",
    "               'Missing text (incorrectly removed by QA)','outcome']\n",
    "    if len(full_cqr_data) == 0 or len(pp_rules_data) == 0: \n",
    "        print('ERROR: Not enough information to complete')\n",
    "        dff = pd.DataFrame(columns = cols)\n",
    "    else: \n",
    "        print('Generating Flag Audit errors!')\n",
    "        df = full_cqr_data.merge(pp_rules_data, on = 'PVID')\n",
    "        df = df.rename(columns = {'COMMENT':'CORRECT_DESCRIPTION'})\n",
    "        cols = ['CQR_AUDIT_DATE',\n",
    "            'USER_EMAIL',\n",
    "            'AUDIT_LEVEL',\n",
    "            'DOMAIN',\n",
    "            'POST_PROCESSED_DESCRIPTION',\n",
    "            'CORRECT_DESCRIPTION',\n",
    "               'FLAGTEXT','RULECREATED']\n",
    "        dff = df.groupby(cols)['VARIANT_PPED_AT','PVID','LINK'].min()            .reset_index()            .rename(columns = {'VARIANT_PPED_AT':'description_PPed_at','PVID':'sample_pvid','LINK':'sample_link'})\n",
    "        dff['Extra text (not removed by QA)'] = dff.apply(lambda x: np.setdiff1d([i.strip('. ') for i in re.split('\\. |\\n|\\! |\\? ', x['POST_PROCESSED_DESCRIPTION']) if i != ''],[i.strip('. ') for i in re.split('\\. |\\n|\\! |\\? ', x['CORRECT_DESCRIPTION']) if i != '']), axis = 1)    \n",
    "        dff['Missing text (incorrectly removed by QA)'] = dff.apply(lambda x: np.setdiff1d([i.strip('. ') for i in re.split('\\. |\\n|\\! |\\? ', x['CORRECT_DESCRIPTION']) if i != ''],[i.strip('. ') for i in re.split('\\. |\\n|\\! |\\? ', x['POST_PROCESSED_DESCRIPTION']) if i != '']), axis = 1)\n",
    "\n",
    "        dff['bad_removal'] = dff.apply(lambda x: x['RULECREATED'] == 'true' and re.sub(\"\\.|\\'|\\,\",'',x['FLAGTEXT'].strip().lower()) in re.sub(\"\\.|\\'|\\,\",'',str(x['Missing text (incorrectly removed by QA)']).strip().lower()),axis = 1)\n",
    "        dff['bad_inclusion'] = dff.apply(lambda x:  x['RULECREATED'] == 'false' and re.sub(\"\\.|\\'|\\,\",'',x['FLAGTEXT'].strip().lower()) in re.sub(\"\\.|\\'|\\,\",'',str(x['Extra text (not removed by QA)']).strip().lower()),axis = 1)\n",
    "        dff['outcome'] = dff.apply(lambda x: 'bad flag removal' if x['bad_removal'] == True else ('bad flag inclusion' if x['bad_inclusion'] == True else 'ok'), axis = 1)\n",
    "        dff['type'] = 'Flag Audit'\n",
    "\n",
    "        print('Success! Generated Flag Audit Errors\\n-------------')    \n",
    "    return dff.loc[:,cols] #dff['outcome'] != 'ok',\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf526fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate final error report\n",
    "def completeErrorReport(speed_audit_errors,flag_audit_errors):\n",
    "    df = pd.concat([speed_audit_errors,flag_audit_errors])[['CQR_AUDIT_DATE',\n",
    "    'USER_EMAIL',\n",
    "    'type',\n",
    "    'AUDIT_LEVEL',\n",
    "    'DOMAIN',\n",
    "    'description_PPed_at',\n",
    "    'sample_pvid',\n",
    "    'sample_link',\n",
    "    'CORRECT_DESCRIPTION',\n",
    "    'QA_DESCRIPTION',\n",
    "    'FLAGTEXT',\n",
    "    'RULECREATED',\n",
    "    'Extra text (not removed by QA)',\n",
    "    'Missing text (incorrectly removed by QA)',\n",
    "    'outcome']]\n",
    "    df = df.sort_values(['DOMAIN','USER_EMAIL'])\n",
    "    \n",
    "    print(df.shape)\n",
    "    \n",
    "    df['CQR_AUDIT_DATE'] = pd.to_datetime(df['CQR_AUDIT_DATE'],utc=True)\n",
    "    df['description_PPed_at'] = pd.to_datetime(df['description_PPed_at'],utc=True)\n",
    "\n",
    "########## Change variable - number of days #############\n",
    "#    df = df.loc[abs((df['CQR_AUDIT_DATE'] - df['description_PPed_at']).dt.days) <= 21] ##default -  only include work done in past week\n",
    "    \n",
    "#    df.loc[df['outcome'].isin(['incorrect speed audit','bad flag removal'])].to_clipboard(index = False)\n",
    "    df.to_clipboard(index = False)\n",
    "    print('Error Report created!')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae7f0b95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR LOGS 09/18/2022 to 09/20/2022\n",
      "\n",
      "Getting CQR incorrect results from Snowflake!\n",
      "Success! Got CQR incorrect results from Snowflake. Number of rows: 431 \n",
      "-------------\n",
      "Getting CQR input data from S3!\n",
      "Pulling from www.rollbicycles.com/partial_www.rollbicycles.com_0919_00_26:12:26:18.csv\n",
      "Pulling from m.nadula.com/m.nadula.com_0913_02_07:02:07:32.csv\n",
      "Pulling from www.ourtruegod.com/partial_www.ourtruegod.com_0916_04_30:04:30:34.csv\n",
      "Pulling from ansonbelt.com/ansonbelt.com_0915_04_19:04:19:24.csv\n",
      "Pulling from branchbasics.com/branchbasics.com_0915_05_09:05:09:39.csv\n",
      "Pulling from nagijewelers.com/nagijewelers.com_0914_00_38:12:38:33.csv\n",
      "Pulling from jaeleacosmetics.com/partial_jaeleacosmetics.com_0919_06_27:06:27:53.csv\n",
      "Pulling from www.tula.com/www.tula.com_0916_02_01:02:01:29.csv\n",
      "Pulling from shop.wisdomofthewombonline.com/shop.wisdomofthewombonline.com_0915_05_08:05:08:39.csv\n",
      "Pulling from dailysale.com/partial_dailysale.com_0914_00_32:12:32:28.csv\n",
      "Pulling from littleseedfarm.com/partial_littleseedfarm.com_0914_04_45:04:45:49.csv\n",
      "Pulling from tkees.com/partial_tkees.com_0919_00_21:12:21:55.csv\n",
      "Pulling from gumps.com/partial_gumps.com_0919_02_26:02:26:09.csv\n",
      "Pulling from paperhouseproductions.com/paperhouseproductions.com_0919_21_47:09:47:01.csv\n",
      "Pulling from www.sheex.com/www.sheex.com_0916_01_35:01:35:45.csv\n",
      "Pulling from johnscrazysocks.com/johnscrazysocks.com_0916_00_31:12:31:32.csv\n",
      "Pulling from www.apeainthepod.com/www.apeainthepod.com_0919_02_19:02:19:35.csv\n",
      "Pulling from www.drbrandtskincare.com/www.drbrandtskincare.com_0920_06_00:06:00:09.csv\n",
      "Pulling from www.livieandluca.com/www.livieandluca.com_0908_01_02:01:02:12.csv\n",
      "Pulling from www.peaceloverally.com/partial_www.peaceloverally.com_0915_00_37:12:37:48.csv\n",
      "Pulling from envystylz.com/envystylz.com_0915_00_22:12:22:57.csv\n",
      "Pulling from www.32degrees.com/partial_www.32degrees.com_0916_01_47:01:47:16.csv\n",
      "Pulling from foxoutfitters.com/partial_foxoutfitters.com_0919_08_42:08:42:34.csv\n",
      "Success! Got CQR input data from S3. Number of rows: 3592 \n",
      "-------------\n",
      "Merging data!\n",
      "Success! Merged data. Number of rows: 379 \n",
      "-------------\n",
      "Getting descriptions data from Snowflake!\n",
      "Success! Got descriptions data from Snowflake. Number of rows: 1558\n",
      "Getting rules data from Snowflake!\n",
      "Success! Got rules data from Snowflake. Number of rows: 37 \n",
      "-------------\n",
      "Generating Speed Audit errors!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/hn/mtn160v16kq8zlz1vr6zxzdh0000gn/T/ipykernel_3530/2414781991.py:30: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dff = df.groupby(tmp_cols)['VARIANT_PPED_AT','PVID','LINK'].min()                .reset_index()                .rename(columns = {'VARIANT_PPED_AT':'description_PPed_at','PVID':'sample_pvid','LINK':'sample_link'})\n",
      "/var/folders/hn/mtn160v16kq8zlz1vr6zxzdh0000gn/T/ipykernel_3530/972459351.py:22: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  dff = df.groupby(cols)['VARIANT_PPED_AT','PVID','LINK'].min()            .reset_index()            .rename(columns = {'VARIANT_PPED_AT':'description_PPed_at','PVID':'sample_pvid','LINK':'sample_link'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Generated Speed Audit Errors\n",
      "-------------\n",
      "Generating Flag Audit errors!\n",
      "Success! Generated Flag Audit Errors\n",
      "-------------\n",
      "(412, 15)\n",
      "Error Report created!\n",
      "Getting all CQR data from Snowflake!\n",
      "Success! Got all CQR data from Snowflake. Number of rows: 7283 \n",
      "-------------\n",
      "Getting CQR input data from S3!\n",
      "Pulling from tkees.com/partial_tkees.com_0919_00_21:12:21:55.csv\n",
      "Pulling from bluechipteam.com/partial_bluechipteam.com_0919_00_33:12:33:11.csv\n",
      "Pulling from ballermerch.com/partial_ballermerch.com_0916_00_25:12:25:34.csv\n",
      "Pulling from shop.barnowl.tech/partial_shop.barnowl.tech_0916_00_36:12:36:57.csv\n",
      "Pulling from gumps.com/partial_gumps.com_0919_02_26:02:26:09.csv\n",
      "Pulling from workthemetal.com/partial_workthemetal.com_0919_21_44:09:44:49.csv\n",
      "Pulling from rkmerch.com/rkmerch.com_0916_01_56:01:56:04.csv\n",
      "Pulling from alltherestaurants.com/partial_alltherestaurants.com_0919_21_57:09:57:33.csv\n",
      "Pulling from strawberryavocados.com/partial_strawberryavocados.com_0915_04_59:04:59:20.csv\n",
      "Pulling from www.buckmason.com/partial_www.buckmason.com_0915_04_22:04:22:56.csv\n",
      "Pulling from nurturemybody.com/partial_nurturemybody.com_0919_08_50:08:50:11.csv\n",
      "Pulling from www.ryanchristianjewelry.com/partial_www.ryanchristianjewelry.com_0916_04_32:04:32:22.csv\n",
      "Pulling from kjaerweis.com/kjaerweis.com_0919_21_42:09:42:42.csv\n",
      "Pulling from www.32degrees.com/partial_www.32degrees.com_0916_01_47:01:47:16.csv\n",
      "Pulling from courserworld.com/partial_courserworld.com_0919_06_22:06:22:56.csv\n",
      "Pulling from www.ourtruegod.com/partial_www.ourtruegod.com_0916_04_30:04:30:34.csv\n",
      "Pulling from www.adornmonde.com/partial_www.adornmonde.com_0913_00_49:12:49:53.csv\n",
      "Pulling from shopravella.com/partial_shopravella.com_0916_00_41:12:41:20.csv\n",
      "Pulling from shopnoble.com/shopnoble.com_0919_00_30:12:30:02.csv\n",
      "Pulling from www.yoox.com/www.yoox.com_0920_20_19:08:19:15.csv\n",
      "Pulling from envystylz.com/envystylz.com_0915_00_22:12:22:57.csv\n",
      "Pulling from thecandlebar.co/partial_thecandlebar.co_0919_19_47:07:47:45.csv\n",
      "Pulling from www.rollbicycles.com/partial_www.rollbicycles.com_0919_00_26:12:26:18.csv\n",
      "Pulling from www.heritagesteel.us/www.heritagesteel.us_0914_09_33:09:33:13.csv\n",
      "Pulling from www.bumpsuit.co/www.bumpsuit.co_0919_02_20:02:20:40.csv\n",
      "Pulling from wordaful.com/partial_wordaful.com_0919_19_43:07:43:26.csv\n",
      "Pulling from thebalm.com/partial_thebalm.com_0919_19_26:07:26:05.csv\n",
      "Pulling from stylebyorion.myshopify.com/partial_stylebyorion.myshopify.com_0916_04_33:04:33:05.csv\n",
      "Pulling from www.drbrandtskincare.com/www.drbrandtskincare.com_0920_06_00:06:00:09.csv\n",
      "Pulling from defleppard.store/partial_defleppard.store_0919_02_28:02:28:03.csv\n",
      "Pulling from ansonbelt.com/ansonbelt.com_0915_04_19:04:19:24.csv\n",
      "Pulling from jacella.com/partial_jacella.com_0919_08_10:08:10:59.csv\n",
      "Pulling from deziskin.com/partial_deziskin.com_0919_06_26:06:26:08.csv\n",
      "Pulling from donut.media/partial_donut.media_0919_08_36:08:36:00.csv\n",
      "Pulling from m.nadula.com/m.nadula.com_0913_02_07:02:07:32.csv\n",
      "Pulling from www.snkrproject.com/partial_www.snkrproject.com_0919_00_23:12:23:30.csv\n",
      "Pulling from www.rewash.com/www.rewash.com_0915_00_29:12:29:46.csv\n",
      "Pulling from www.carlinbrotherscoffee.com/partial_www.carlinbrotherscoffee.com_0919_08_40:08:40:07.csv\n",
      "Pulling from texproud.com/partial_texproud.com_0919_00_24:12:24:28.csv\n",
      "Pulling from roseboxnyc.com/roseboxnyc.com_0919_19_29:07:29:06.csv\n",
      "Pulling from www.sheex.com/www.sheex.com_0916_01_35:01:35:45.csv\n",
      "Pulling from americanfitnesscouture.com/partial_americanfitnesscouture.com_0919_06_13:06:13:23.csv\n",
      "Pulling from paperhouseproductions.com/paperhouseproductions.com_0919_21_47:09:47:01.csv\n",
      "Pulling from shop.wisdomofthewombonline.com/shop.wisdomofthewombonline.com_0915_05_08:05:08:39.csv\n",
      "Pulling from weareuni.com/partial_weareuni.com_0919_06_10:06:10:23.csv\n",
      "Pulling from diamondaupair.com/partial_diamondaupair.com_0919_19_35:07:35:26.csv\n",
      "Pulling from www.livieandluca.com/www.livieandluca.com_0908_01_02:01:02:12.csv\n",
      "Pulling from attngrace.com/partial_attngrace.com_0916_01_59:01:59:08.csv\n",
      "Pulling from dailysale.com/partial_dailysale.com_0914_00_32:12:32:28.csv\n",
      "Pulling from jaeleacosmetics.com/partial_jaeleacosmetics.com_0919_06_27:06:27:53.csv\n",
      "Pulling from estasbeauty.com/partial_estasbeauty.com_0919_06_19:06:19:43.csv\n",
      "Pulling from topofthemornincoffee.com/partial_topofthemornincoffee.com_0919_08_43:08:43:34.csv\n",
      "Pulling from branchbasics.com/branchbasics.com_0915_05_09:05:09:39.csv\n",
      "Pulling from blockofgear.com/blockofgear.com_0916_00_29:12:29:33.csv\n",
      "Pulling from www.tula.com/www.tula.com_0916_02_01:02:01:29.csv\n",
      "Pulling from grittysoul.com/grittysoul.com_0916_04_31:04:31:42.csv\n",
      "Pulling from johnscrazysocks.com/johnscrazysocks.com_0916_00_31:12:31:32.csv\n",
      "Pulling from www.beforebedheadz.com/partial_www.beforebedheadz.com_0919_00_32:12:32:25.csv\n",
      "Pulling from littleseedfarm.com/partial_littleseedfarm.com_0914_04_45:04:45:49.csv\n",
      "Pulling from manlybands.com/manlybands.com_0914_05_27:05:27:13.csv\n",
      "Pulling from nagijewelers.com/nagijewelers.com_0914_00_38:12:38:33.csv\n",
      "Pulling from b-selfie.com/partial_b-selfie.com_0919_00_25:12:25:17.csv\n",
      "Pulling from tuffring.com/partial_tuffring.com_0919_19_37:07:37:49.csv\n",
      "Pulling from deadandcoshop.com/partial_deadandcoshop.com_0919_08_14:08:14:45.csv\n",
      "Pulling from foxoutfitters.com/partial_foxoutfitters.com_0919_08_42:08:42:34.csv\n",
      "Pulling from www.apeainthepod.com/www.apeainthepod.com_0919_02_19:02:19:35.csv\n",
      "Pulling from www.kasper.com/partial_www.kasper.com_0916_00_20:12:20:40.csv\n",
      "Pulling from artphenomena.art/partial_artphenomena.art_0916_01_59:01:59:59.csv\n",
      "Pulling from besynchro.com/partial_besynchro.com_0919_08_45:08:45:33.csv\n",
      "Pulling from thensvne.com/thensvne.com_0920_09_06:09:06:04.csv\n",
      "Pulling from dancewithphil.com/partial_dancewithphil.com_0919_00_31:12:31:12.csv\n",
      "Pulling from www.tiyproducts.com/partial_www.tiyproducts.com_0915_04_27:04:27:58.csv\n",
      "Pulling from www.getrootlogic.com/www.getrootlogic.com_0919_00_33:12:33:58.csv\n",
      "Pulling from www.ksahai.com/partial_www.ksahai.com_0919_19_31:07:31:08.csv\n",
      "Pulling from bustajackgolf.com/partial_bustajackgolf.com_0919_02_23:02:23:37.csv\n",
      "Pulling from www.tommyjohn.com/www.tommyjohn.com_0920_07_39:07:39:11.csv\n",
      "Pulling from www.peaceloverally.com/partial_www.peaceloverally.com_0915_00_37:12:37:48.csv\n",
      "Pulling from sillyfeet.com/partial_sillyfeet.com_0919_06_16:06:16:56.csv\n",
      "Pulling from reflektskincare.com/partial_reflektskincare.com_0919_08_47:08:47:45.csv\n",
      "Pulling from omarcbolden.com/partial_omarcbolden.com_0919_19_23:07:23:58.csv\n",
      "Pulling from www.jogoball.com/partial_www.jogoball.com_0919_06_24:06:24:27.csv\n",
      "Pulling from 22below.us/partial_22below.us_0919_08_38:08:38:17.csv\n",
      "Pulling from eukawell.com/partial_eukawell.com_0919_06_11:06:11:21.csv\n",
      "Pulling from milkdust.com/milkdust.com_0920_05_56:05:56:51.csv\n",
      "Pulling from www.sommeinstitute.com/www.sommeinstitute.com_0919_08_20:08:20:39.csv\n",
      "Success! Got CQR input data from S3. Number of rows: 10998 \n",
      "-------------\n",
      "Generating QA Sample Size Count\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fb_product_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m tcqr_count \u001b[38;5;241m=\u001b[39m getCQRCount(date_in,date_out)\n\u001b[1;32m     14\u001b[0m cqr_count \u001b[38;5;241m=\u001b[39m getCQRInputs(tcqr_count)\n\u001b[0;32m---> 15\u001b[0m audit_count \u001b[38;5;241m=\u001b[39m \u001b[43mgenerateAuditCountQA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcqr_count\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpp_desc_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [21], line 14\u001b[0m, in \u001b[0;36mgenerateAuditCountQA\u001b[0;34m(cqr_count, pp_desc_data)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenerating QA Sample Size Count\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mcqr_count\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpp_desc_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfb_product_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCOMMENT\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCORRECT_DESCRIPTION\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m     16\u001b[0m     dff \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSER_EMAIL\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfb_product_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique() \n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.7/libexec/lib/python3.10/site-packages/pandas/core/frame.py:9354\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m   9335\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   9336\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   9337\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   9350\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   9351\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   9352\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m-> 9354\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9357\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9362\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9363\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9364\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9365\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9366\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9367\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9368\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.7/libexec/lib/python3.10/site-packages/pandas/core/reshape/merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.7/libexec/lib/python3.10/site-packages/pandas/core/reshape/merge.py:700\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    695\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    696\u001b[0m (\n\u001b[1;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.7/libexec/lib/python3.10/site-packages/pandas/core/reshape/merge.py:1097\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_rkey(rk):\n\u001b[1;32m   1096\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1097\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(\u001b[43mright\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_label_or_level_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrk\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m         right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.7/libexec/lib/python3.10/site-packages/pandas/core/generic.py:1840\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1838\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\u001b[38;5;241m.\u001b[39mget_level_values(key)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1839\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1843\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'fb_product_id'"
     ]
    }
   ],
   "source": [
    "date_in = '09/18/2022'\n",
    "# date_out = date_in\n",
    "date_out = '09/20/2022'\n",
    "\n",
    "print(f'ERROR LOGS {date_in} to {date_out}\\n')\n",
    "cqr_results = getCQRResults(date_in,date_out)\n",
    "cqr_inputs = getCQRInputs(cqr_results)\n",
    "full_cqr_data = mergeCQRData(cqr_results, cqr_inputs)\n",
    "\n",
    "pp_desc_data, pp_rules_data = getPPQAData(cqr_results['PVID'].unique().tolist())\n",
    "error_count,speed_audit_errors = generateSpeedAuditErrors(cqr_results, pp_desc_data)\n",
    "\n",
    "flag_audit_errors = generateFlagAuditErrors(full_cqr_data, pp_rules_data)\n",
    "df = completeErrorReport(speed_audit_errors,flag_audit_errors)\n",
    "\n",
    "tcqr_count = getCQRCount(date_in,date_out)\n",
    "cqr_count = getCQRInputs(tcqr_count)\n",
    "audit_count = generateAuditCountQA(cqr_count, pp_desc_data)\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "#df.loc[df['outcome'].isin(['incorrect speed audit','bad flag removal'])].to_clipboard(index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48063eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = audit_count.to_frame()\n",
    "ac.to_clipboard(index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38ed7636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CATALOG_ID</th>\n",
       "      <th>DOMAIN</th>\n",
       "      <th>AUDIT_ID</th>\n",
       "      <th>CQR_AUDIT_DATE</th>\n",
       "      <th>BODY_S3_KEY</th>\n",
       "      <th>VARIANT_ID</th>\n",
       "      <th>ATTRIBUTE</th>\n",
       "      <th>ATTRIBUTE_GRADE</th>\n",
       "      <th>REASON</th>\n",
       "      <th>COMMENT</th>\n",
       "      <th>PVID</th>\n",
       "      <th>LINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2785268745061885</td>\n",
       "      <td>tkees.com</td>\n",
       "      <td>6327ef15bccd1c57b6372db3</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>tkees.com/partial_tkees.com_0919_00_21:12:21:5...</td>\n",
       "      <td>18230650830921</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>tkees.com!18230650830921</td>\n",
       "      <td>https://tkees.com/products/mini-neons?variant=...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538362037744988</td>\n",
       "      <td>bluechipteam.com</td>\n",
       "      <td>6328348106210efcabed5475</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>bluechipteam.com/partial_bluechipteam.com_0919...</td>\n",
       "      <td>42018851487939</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>bluechipteam.com!42018851487939</td>\n",
       "      <td>https://bluechipteam.com/products/monty-montgo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292992665163720</td>\n",
       "      <td>ballermerch.com</td>\n",
       "      <td>63240cbc7b603dacf06ffa72</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>ballermerch.com/partial_ballermerch.com_0916_0...</td>\n",
       "      <td>40679927054520</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ballermerch.com!40679927054520</td>\n",
       "      <td>https://ballermerch.com/products/cuffed-beanie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290437888446813</td>\n",
       "      <td>shop.barnowl.tech</td>\n",
       "      <td>6327cc5acbf41d571c3e0a85</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>shop.barnowl.tech/partial_shop.barnowl.tech_09...</td>\n",
       "      <td>39728642130002</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>shop.barnowl.tech!39728642130002</td>\n",
       "      <td>https://shop.barnowl.tech/products/barn-owl-un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>911984675868483</td>\n",
       "      <td>gumps.com</td>\n",
       "      <td>6328715dc806030e28e72937</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>gumps.com/partial_gumps.com_0919_02_26:02:26:0...</td>\n",
       "      <td>31788965986389</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>gumps.com!31788965986389</td>\n",
       "      <td>https://gumps.com/products/necklace-ss-blue-to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7278</th>\n",
       "      <td>255457501904489</td>\n",
       "      <td>roseboxnyc.com</td>\n",
       "      <td>6328f7060f35beb509c38ff9</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>roseboxnyc.com/roseboxnyc.com_0919_19_29:07:29...</td>\n",
       "      <td>571</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>www.oakrivercompany.com!571</td>\n",
       "      <td>https://www.oakrivercompany.com/store/p571/Buc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>302351757209070</td>\n",
       "      <td>www.livieandluca.com</td>\n",
       "      <td>6319f0d7c36b0b4e47ac1d99</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>www.livieandluca.com/www.livieandluca.com_0908...</td>\n",
       "      <td>39389877633095</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>www.livieandluca.com!39389877633095</td>\n",
       "      <td>https://www.livieandluca.com/products/ali-boot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7280</th>\n",
       "      <td>576304583071755</td>\n",
       "      <td>www.ryanchristianjewelry.com</td>\n",
       "      <td>63247b097b603dbf179024b9</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>www.ryanchristianjewelry.com/partial_www.ryanc...</td>\n",
       "      <td>31300746608738</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ryanchristiandesigns.com!31300746608738</td>\n",
       "      <td>https://ryanchristiandesigns.com/products/ster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7281</th>\n",
       "      <td>1111616945602561</td>\n",
       "      <td>alltherestaurants.com</td>\n",
       "      <td>63293c0346db09131c733816</td>\n",
       "      <td>2022-09-20</td>\n",
       "      <td>alltherestaurants.com/partial_alltherestaurant...</td>\n",
       "      <td>39277492011071</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>alltherestaurants.com!39277492011071</td>\n",
       "      <td>https://alltherestaurants.com/products/hop-kee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>479696789062763</td>\n",
       "      <td>thebalm.com</td>\n",
       "      <td>6328d428ae0dd8721ee03352</td>\n",
       "      <td>2022-09-19</td>\n",
       "      <td>thebalm.com/partial_thebalm.com_0919_19_26:07:...</td>\n",
       "      <td>19252403404867</td>\n",
       "      <td>description</td>\n",
       "      <td>Good</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>thebalm.com!19252403404867</td>\n",
       "      <td>https://thebalm.com/products/copy-of-timebalm-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7283 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CATALOG_ID                        DOMAIN  \\\n",
       "0     2785268745061885                     tkees.com   \n",
       "1      538362037744988              bluechipteam.com   \n",
       "2      292992665163720               ballermerch.com   \n",
       "3      290437888446813             shop.barnowl.tech   \n",
       "4      911984675868483                     gumps.com   \n",
       "...                ...                           ...   \n",
       "7278   255457501904489                roseboxnyc.com   \n",
       "7279   302351757209070          www.livieandluca.com   \n",
       "7280   576304583071755  www.ryanchristianjewelry.com   \n",
       "7281  1111616945602561         alltherestaurants.com   \n",
       "7282   479696789062763                   thebalm.com   \n",
       "\n",
       "                      AUDIT_ID CQR_AUDIT_DATE  \\\n",
       "0     6327ef15bccd1c57b6372db3     2022-09-19   \n",
       "1     6328348106210efcabed5475     2022-09-19   \n",
       "2     63240cbc7b603dacf06ffa72     2022-09-19   \n",
       "3     6327cc5acbf41d571c3e0a85     2022-09-20   \n",
       "4     6328715dc806030e28e72937     2022-09-20   \n",
       "...                        ...            ...   \n",
       "7278  6328f7060f35beb509c38ff9     2022-09-20   \n",
       "7279  6319f0d7c36b0b4e47ac1d99     2022-09-19   \n",
       "7280  63247b097b603dbf179024b9     2022-09-20   \n",
       "7281  63293c0346db09131c733816     2022-09-20   \n",
       "7282  6328d428ae0dd8721ee03352     2022-09-19   \n",
       "\n",
       "                                            BODY_S3_KEY      VARIANT_ID  \\\n",
       "0     tkees.com/partial_tkees.com_0919_00_21:12:21:5...  18230650830921   \n",
       "1     bluechipteam.com/partial_bluechipteam.com_0919...  42018851487939   \n",
       "2     ballermerch.com/partial_ballermerch.com_0916_0...  40679927054520   \n",
       "3     shop.barnowl.tech/partial_shop.barnowl.tech_09...  39728642130002   \n",
       "4     gumps.com/partial_gumps.com_0919_02_26:02:26:0...  31788965986389   \n",
       "...                                                 ...             ...   \n",
       "7278  roseboxnyc.com/roseboxnyc.com_0919_19_29:07:29...             571   \n",
       "7279  www.livieandluca.com/www.livieandluca.com_0908...  39389877633095   \n",
       "7280  www.ryanchristianjewelry.com/partial_www.ryanc...  31300746608738   \n",
       "7281  alltherestaurants.com/partial_alltherestaurant...  39277492011071   \n",
       "7282  thebalm.com/partial_thebalm.com_0919_19_26:07:...  19252403404867   \n",
       "\n",
       "        ATTRIBUTE ATTRIBUTE_GRADE REASON COMMENT  \\\n",
       "0     description            Good   None    None   \n",
       "1     description            Good   None    None   \n",
       "2     description            Good   None    None   \n",
       "3     description            Good   None    None   \n",
       "4     description            Good   None    None   \n",
       "...           ...             ...    ...     ...   \n",
       "7278  description            Good   None    None   \n",
       "7279  description            Good   None    None   \n",
       "7280  description            Good   None    None   \n",
       "7281  description            Good   None    None   \n",
       "7282  description            Good   None    None   \n",
       "\n",
       "                                         PVID  \\\n",
       "0                    tkees.com!18230650830921   \n",
       "1             bluechipteam.com!42018851487939   \n",
       "2              ballermerch.com!40679927054520   \n",
       "3            shop.barnowl.tech!39728642130002   \n",
       "4                    gumps.com!31788965986389   \n",
       "...                                       ...   \n",
       "7278              www.oakrivercompany.com!571   \n",
       "7279      www.livieandluca.com!39389877633095   \n",
       "7280  ryanchristiandesigns.com!31300746608738   \n",
       "7281     alltherestaurants.com!39277492011071   \n",
       "7282               thebalm.com!19252403404867   \n",
       "\n",
       "                                                   LINK  \n",
       "0     https://tkees.com/products/mini-neons?variant=...  \n",
       "1     https://bluechipteam.com/products/monty-montgo...  \n",
       "2     https://ballermerch.com/products/cuffed-beanie...  \n",
       "3     https://shop.barnowl.tech/products/barn-owl-un...  \n",
       "4     https://gumps.com/products/necklace-ss-blue-to...  \n",
       "...                                                 ...  \n",
       "7278  https://www.oakrivercompany.com/store/p571/Buc...  \n",
       "7279  https://www.livieandluca.com/products/ali-boot...  \n",
       "7280  https://ryanchristiandesigns.com/products/ster...  \n",
       "7281  https://alltherestaurants.com/products/hop-kee...  \n",
       "7282  https://thebalm.com/products/copy-of-timebalm-...  \n",
       "\n",
       "[7283 rows x 12 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tcqr_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cba5ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USER_EMAIL\n",
       "abegael.intertas@teleworkph-mails.com          1\n",
       "adeline.santos@teleworkph-mails.com            1\n",
       "alvin.dagdagan@teleworkph-mails.com            3\n",
       "christian.mitu@teleworkph-mails.com            2\n",
       "danilo.gatuz@teleworkph-mails.com             37\n",
       "earlson.miquiabas@contractors.scale.com       24\n",
       "gabriela.almaraz@contractors.scale.com        26\n",
       "german.toledo@contractors.scale.com           63\n",
       "jaspher.abayon@teleworkph-mails.com            5\n",
       "jericlopez.lopez@teleworkph-mails.com          1\n",
       "johntristan.faustino@teleworkph-mails.com      1\n",
       "jose.bangay@contractors.scale.com             22\n",
       "karenann.astorga@teleworkph-mails.com          5\n",
       "karla.nunez@contractors.scale.com              6\n",
       "kent.mozo@contractors.scale.com                6\n",
       "kyla.mananghaya@teleworkph-mails.com           7\n",
       "liezel.mangulabnan@teleworkph-mails.com        1\n",
       "lucia.ledesma@contractors.scale.com            4\n",
       "lyndon.tojeno@contractors.scale.com            9\n",
       "marco.escaroz@contractors.scale.com           11\n",
       "mario.frias@contractors.scale.com             10\n",
       "mitzifaye.borja@teleworkph-mails.com          27\n",
       "reyman.cajayon@teleworkph-mails.com           27\n",
       "ruchel.casero@contractors.scale.com          166\n",
       "samantha.couoh@contractors.scale.com           9\n",
       "tedrick.barbosa@teleworkph-mails.com          26\n",
       "Name: PVID, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c8e45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
